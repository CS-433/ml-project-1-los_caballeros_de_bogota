{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.helpers import*\n",
    "from implementations import*\n",
    "\n",
    "\n",
    "data_path_te = 'data/test.csv'\n",
    "data_path_tr = 'data/train.csv'\n",
    "data_path_te = 'data/sample-submission.csv'\n",
    "\n",
    "\n",
    "\n",
    "y_tr, input_data_tr, ids_tr =load_csv_data(data_path_tr, sub_sample=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_tr[y_tr ==-1]= 0\n",
    "\n",
    "def normalize_dat(x):\n",
    "    normalized = (x-np.mean(x, axis=0))/np.std(x, axis=0)\n",
    "    return normalized\n",
    "\n",
    "print(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(input_data_te)\n",
    "\n",
    "def predict(x, w):\n",
    "    y_pred = np.empty_like(x @ w)\n",
    "    y_pred[sigmoid(x @ w)  > 0.5] = 1\n",
    "    y_pred[sigmoid(x @ w) <= 0.5] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(input_data_te)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "def compute_f1_score(y_true, y_pred):\n",
    "    tp = np.sum((y_pred == 1) & (y_pred == y_true))\n",
    "    fp = np.sum((y_pred == 1) & (y_pred != y_true))\n",
    "    fn = np.sum((y_pred == 0) & (y_pred != y_true))\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "    \n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "\n",
    "    >>> build_k_indices(np.array([1., 2., 3., 4.]), 2, 1)\n",
    "    array([[3, 2],\n",
    "           [0, 1]])\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(568238, 0), dtype=float64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tx_tr = normalize_dat(input_data_tr)\n",
    "tx_te = normalize_dat(input_data_te)\n",
    "\n",
    "input_data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, max_iters, gamma):\n",
    "    \"\"\"return the loss of ridge regression for a fold corresponding to k_indices\n",
    "    \n",
    "    Args:\n",
    "        y:          shape=(N,)\n",
    "        x:          shape=(N,D)\n",
    "        k_indices:  2D array returned by build_k_indices()\n",
    "        k:          scalar, the k-th fold (N.B.: not to confused with k_fold which is the fold nums)\n",
    "        lambda_:    scalar, cf. ridge_regression()\n",
    "        degree:     scalar, cf. build_poly()\n",
    "\n",
    "    Returns:\n",
    "        train and test root mean square errors rmse = sqrt(2 mse)\n",
    "\n",
    "    >>> cross_validation(np.array([1.,2.,3.,4.]), np.array([6.,7.,8.,9.]), np.array([[3,2], [0,1]]), 1, 2, 3)\n",
    "    (0.019866645527597114, 0.33555914361295175)\n",
    "    \"\"\"\n",
    "    \n",
    "    # get k'th subgroup in test, others in train: \n",
    "    x_test = x[k_indices[k], :]\n",
    "    y_test = y[k_indices[k]]\n",
    "    \n",
    "    x_train = np.delete(x, k_indices[k], axis=0)\n",
    "    y_train = np.delete(y, k_indices[k])\n",
    "\n",
    "    # form data with polynomial degree:\n",
    "    \n",
    "    num_samples_train = len(y_train)\n",
    "    num_samples_test = len(y_test)\n",
    "    tx_train = np.c_[np.ones(num_samples_train), x_train]\n",
    "    tx_test = np.c_[np.ones(num_samples_test), x_test]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    initial_w = np.ones(tx_train.shape[1])\n",
    "\n",
    "    # ridge regression: \n",
    "    print(tx_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(initial_w.shape)\n",
    "    w,loss_tr = reg_logistic_regression(y_train, tx_train, lambda_, initial_w, max_iters, gamma)\n",
    "    \n",
    "    acc = compute_accuracy(y_test, predict(tx_test, w))\n",
    "    \n",
    "    f1 = compute_f1_score(y_test, predict(tx_test, w))\n",
    "\n",
    "    # calculate the loss for train and test data: \n",
    "    \n",
    "    loss_te = compute_loss(y_test, tx_test, w, 'log')\n",
    "\n",
    "    return loss_tr, loss_te, w, acc, f1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.475473728010437, w0=0.9999927846105674, w1=1.0000004075963767\n",
      "GD iter. 1/99: loss=4.475403215568873, w0=0.999985569019636, w1=1.0000008151226383\n",
      "GD iter. 2/99: loss=4.4753327006215935, w0=0.9999783532271997, w1=1.0000012225787827\n",
      "GD iter. 3/99: loss=4.4752621831765484, w0=0.9999711372332526, w1=1.0000016299648076\n",
      "GD iter. 4/99: loss=4.475191663245682, w0=0.9999639210377885, w1=1.000002037280711\n",
      "GD iter. 5/99: loss=4.475121140808542, w0=0.9999567046408014, w1=1.0000024445264908\n",
      "GD iter. 6/99: loss=4.475050615877096, w0=0.9999494880422852, w1=1.0000028517021446\n",
      "GD iter. 7/99: loss=4.474980088450867, w0=0.9999422712422339, w1=1.0000032588076706\n",
      "GD iter. 8/99: loss=4.4749095585345655, w0=0.9999350542406413, w1=1.0000036658430667\n",
      "GD iter. 9/99: loss=4.474839026116921, w0=0.9999278370375015, w1=1.0000040728083304\n",
      "GD iter. 10/99: loss=4.474768491205013, w0=0.9999206196328084, w1=1.00000447970346\n",
      "GD iter. 11/99: loss=4.474697953798819, w0=0.999913402026556, w1=1.000004886528453\n",
      "GD iter. 12/99: loss=4.474627413895306, w0=0.9999061842187381, w1=1.0000052932833075\n",
      "GD iter. 13/99: loss=4.4745568714918855, w0=0.9998989662093487, w1=1.0000056999680214\n",
      "GD iter. 14/99: loss=4.474486326602829, w0=0.9998917479983818, w1=1.0000061065825923\n",
      "GD iter. 15/99: loss=4.474415779199827, w0=0.9998845295858312, w1=1.0000065131270184\n",
      "GD iter. 16/99: loss=4.474345229315933, w0=0.9998773109716909, w1=1.0000069196012973\n",
      "GD iter. 17/99: loss=4.474274676929023, w0=0.9998700921559548, w1=1.000007326005427\n",
      "GD iter. 18/99: loss=4.474204122051601, w0=0.9998628731386169, w1=1.0000077323394054\n",
      "GD iter. 19/99: loss=4.474133564680541, w0=0.9998556539196711, w1=1.0000081386032305\n",
      "GD iter. 20/99: loss=4.4740630048114, w0=0.9998484344991113, w1=1.0000085447968998\n",
      "GD iter. 21/99: loss=4.473992442453978, w0=0.9998412148769316, w1=1.0000089509204115\n",
      "GD iter. 22/99: loss=4.4739218775845515, w0=0.9998339950531256, w1=1.0000093569737634\n",
      "GD iter. 23/99: loss=4.473851310229082, w0=0.9998267750276876, w1=1.000009762956953\n",
      "GD iter. 24/99: loss=4.4737807403869985, w0=0.9998195548006114, w1=1.0000101688699787\n",
      "GD iter. 25/99: loss=4.473710168032617, w0=0.9998123343718908, w1=1.000010574712838\n",
      "GD iter. 26/99: loss=4.473639593199974, w0=0.9998051137415199, w1=1.000010980485529\n",
      "GD iter. 27/99: loss=4.473569015854439, w0=0.9997978929094926, w1=1.0000113861880495\n",
      "GD iter. 28/99: loss=4.4734984360269365, w0=0.9997906718758028, w1=1.0000117918203975\n",
      "GD iter. 29/99: loss=4.47342785370174, w0=0.9997834506404445, w1=1.0000121973825704\n",
      "GD iter. 30/99: loss=4.473357268887631, w0=0.9997762292034115, w1=1.0000126028745666\n",
      "GD iter. 31/99: loss=4.47328668155869, w0=0.9997690075646978, w1=1.0000130082963836\n",
      "GD iter. 32/99: loss=4.47321609175676, w0=0.9997617857242973, w1=1.0000134136480197\n",
      "GD iter. 33/99: loss=4.473145499446322, w0=0.9997545636822041, w1=1.0000138189294723\n",
      "GD iter. 34/99: loss=4.473074904646933, w0=0.9997473414384118, w1=1.0000142241407395\n",
      "GD iter. 35/99: loss=4.473004307351567, w0=0.9997401189929146, w1=1.000014629281819\n",
      "GD iter. 36/99: loss=4.472933707560842, w0=0.9997328963457064, w1=1.000015034352709\n",
      "GD iter. 37/99: loss=4.472863105271303, w0=0.999725673496781, w1=1.000015439353407\n",
      "GD iter. 38/99: loss=4.472792500494547, w0=0.9997184504461324, w1=1.000015844283911\n",
      "GD iter. 39/99: loss=4.472721893213982, w0=0.9997112271937546, w1=1.000016249144219\n",
      "GD iter. 40/99: loss=4.4726512834437955, w0=0.9997040037396414, w1=1.0000166539343287\n",
      "GD iter. 41/99: loss=4.472580671185365, w0=0.9996967800837868, w1=1.000017058654238\n",
      "GD iter. 42/99: loss=4.472510056423983, w0=0.9996895562261848, w1=1.000017463303945\n",
      "GD iter. 43/99: loss=4.4724394391661, w0=0.9996823321668292, w1=1.000017867883447\n",
      "GD iter. 44/99: loss=4.4723688194251165, w0=0.999675107905714, w1=1.0000182723927424\n",
      "GD iter. 45/99: loss=4.4722981971738704, w0=0.9996678834428331, w1=1.0000186768318289\n",
      "GD iter. 46/99: loss=4.472227572444819, w0=0.9996606587781804, w1=1.0000190812007044\n",
      "GD iter. 47/99: loss=4.472156945202003, w0=0.9996534339117499, w1=1.0000194854993667\n",
      "GD iter. 48/99: loss=4.472086315478985, w0=0.9996462088435354, w1=1.0000198897278136\n",
      "GD iter. 49/99: loss=4.472015683258706, w0=0.999638983573531, w1=1.0000202938860432\n",
      "GD iter. 50/99: loss=4.471945048550274, w0=0.9996317581017304, w1=1.0000206979740531\n",
      "GD iter. 51/99: loss=4.471874411325801, w0=0.9996245324281278, w1=1.0000211019918415\n",
      "GD iter. 52/99: loss=4.4718037716319845, w0=0.9996173065527169, w1=1.0000215059394058\n",
      "GD iter. 53/99: loss=4.471733129429761, w0=0.9996100804754916, w1=1.0000219098167442\n",
      "GD iter. 54/99: loss=4.471662484739755, w0=0.999602854196446, w1=1.0000223136238544\n",
      "GD iter. 55/99: loss=4.47159183755257, w0=0.999595627715574, w1=1.0000227173607343\n",
      "GD iter. 56/99: loss=4.471521187875863, w0=0.9995884010328694, w1=1.000023121027382\n",
      "GD iter. 57/99: loss=4.471450535704443, w0=0.9995811741483261, w1=1.0000235246237952\n",
      "GD iter. 58/99: loss=4.471379881029431, w0=0.9995739470619383, w1=1.0000239281499717\n",
      "GD iter. 59/99: loss=4.4713092238719305, w0=0.9995667197736996, w1=1.0000243316059092\n",
      "GD iter. 60/99: loss=4.471238564216312, w0=0.9995594922836041, w1=1.0000247349916058\n",
      "GD iter. 61/99: loss=4.471167902064103, w0=0.9995522645916456, w1=1.0000251383070595\n",
      "GD iter. 62/99: loss=4.471097237422279, w0=0.9995450366978181, w1=1.0000255415522679\n",
      "GD iter. 63/99: loss=4.471026570287845, w0=0.9995378086021156, w1=1.0000259447272288\n",
      "GD iter. 64/99: loss=4.470955900652036, w0=0.9995305803045319, w1=1.0000263478319404\n",
      "GD iter. 65/99: loss=4.470885228524756, w0=0.9995233518050609, w1=1.0000267508664005\n",
      "GD iter. 66/99: loss=4.470814553902657, w0=0.9995161231036966, w1=1.0000271538306067\n",
      "GD iter. 67/99: loss=4.470743876793678, w0=0.999508894200433, w1=1.000027556724557\n",
      "GD iter. 68/99: loss=4.470673197189211, w0=0.9995016650952637, w1=1.000027959548249\n",
      "GD iter. 69/99: loss=4.470602515089942, w0=0.999494435788183, w1=1.000028362301681\n",
      "GD iter. 70/99: loss=4.470531830497787, w0=0.9994872062791845, w1=1.0000287649848507\n",
      "GD iter. 71/99: loss=4.470461143405983, w0=0.9994799765682624, w1=1.000029167597756\n",
      "GD iter. 72/99: loss=4.470390453831035, w0=0.9994727466554104, w1=1.0000295701403947\n",
      "GD iter. 73/99: loss=4.470319761751848, w0=0.9994655165406225, w1=1.0000299726127646\n",
      "GD iter. 74/99: loss=4.470249067183991, w0=0.9994582862238927, w1=1.0000303750148638\n",
      "GD iter. 75/99: loss=4.470178370126559, w0=0.9994510557052146, w1=1.0000307773466899\n",
      "GD iter. 76/99: loss=4.470107670566004, w0=0.9994438249845825, w1=1.0000311796082408\n",
      "GD iter. 77/99: loss=4.470036968525657, w0=0.9994365940619901, w1=1.0000315817995145\n",
      "GD iter. 78/99: loss=4.469966263973069, w0=0.9994293629374315, w1=1.0000319839205087\n",
      "GD iter. 79/99: loss=4.46989555694804, w0=0.9994221316109003, w1=1.0000323859712215\n",
      "GD iter. 80/99: loss=4.469824847419395, w0=0.9994149000823906, w1=1.0000327879516504\n",
      "GD iter. 81/99: loss=4.469754135398562, w0=0.9994076683518964, w1=1.0000331898617936\n",
      "GD iter. 82/99: loss=4.46968342088027, w0=0.9994004364194115, w1=1.0000335917016487\n",
      "GD iter. 83/99: loss=4.469612703878127, w0=0.9993932042849297, w1=1.0000339934712137\n",
      "GD iter. 84/99: loss=4.4695419843759785, w0=0.9993859719484451, w1=1.0000343951704864\n",
      "GD iter. 85/99: loss=4.469471262378249, w0=0.9993787394099517, w1=1.0000347967994647\n",
      "GD iter. 86/99: loss=4.469400537890464, w0=0.9993715066694432, w1=1.0000351983581466\n",
      "GD iter. 87/99: loss=4.469329810917796, w0=0.9993642737269136, w1=1.0000355998465298\n",
      "GD iter. 88/99: loss=4.46925908144301, w0=0.9993570405823567, w1=1.0000360012646121\n",
      "GD iter. 89/99: loss=4.469188349478869, w0=0.9993498072357666, w1=1.0000364026123916\n",
      "GD iter. 90/99: loss=4.469117615022058, w0=0.9993425736871371, w1=1.000036803889866\n",
      "GD iter. 91/99: loss=4.469046878072866, w0=0.9993353399364621, w1=1.000037205097033\n",
      "GD iter. 92/99: loss=4.468976138625677, w0=0.9993281059837356, w1=1.0000376062338907\n",
      "GD iter. 93/99: loss=4.468905396687709, w0=0.9993208718289514, w1=1.000038007300437\n",
      "GD iter. 94/99: loss=4.468834652261839, w0=0.9993136374721034, w1=1.0000384082966693\n",
      "GD iter. 95/99: loss=4.468763905340625, w0=0.9993064029131857, w1=1.000038809222586\n",
      "GD iter. 96/99: loss=4.468693155928639, w0=0.999299168152192, w1=1.0000392100781847\n",
      "GD iter. 97/99: loss=4.468622404018736, w0=0.9992919331891162, w1=1.0000396108634635\n",
      "GD iter. 98/99: loss=4.468551649627908, w0=0.9992846980239524, w1=1.0000400115784198\n",
      "GD iter. 99/99: loss=4.468480892726106, w0=0.9992774626566944, w1=1.000040412223052\n",
      "0.60092\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.473499820066508, w0=0.9999928703094458, w1=1.000000329810975\n",
      "GD iter. 1/99: loss=4.473429314329043, w0=0.9999857404177822, w1=1.0000006595510436\n",
      "GD iter. 2/99: loss=4.473358806089001, w0=0.9999786103250031, w1=1.0000009892202038\n",
      "GD iter. 3/99: loss=4.473288295339977, w0=0.9999714800311026, w1=1.0000013188184536\n",
      "GD iter. 4/99: loss=4.473217782096625, w0=0.9999643495360746, w1=1.0000016483457905\n",
      "GD iter. 5/99: loss=4.473147266344284, w0=0.9999572188399132, w1=1.0000019778022127\n",
      "GD iter. 6/99: loss=4.473076748085996, w0=0.9999500879426123, w1=1.0000023071877178\n",
      "GD iter. 7/99: loss=4.47300622733836, w0=0.999942956844166, w1=1.0000026365023038\n",
      "GD iter. 8/99: loss=4.472935704073048, w0=0.9999358255445683, w1=1.0000029657459686\n",
      "GD iter. 9/99: loss=4.472865178314954, w0=0.999928694043813, w1=1.0000032949187099\n",
      "GD iter. 10/99: loss=4.472794650051724, w0=0.9999215623418943, w1=1.0000036240205255\n",
      "GD iter. 11/99: loss=4.472724119289489, w0=0.9999144304388061, w1=1.0000039530514133\n",
      "GD iter. 12/99: loss=4.4726535860163255, w0=0.9999072983345424, w1=1.0000042820113713\n",
      "GD iter. 13/99: loss=4.47258305024166, w0=0.9999001660290973, w1=1.0000046109003973\n",
      "GD iter. 14/99: loss=4.472512511970077, w0=0.9998930335224646, w1=1.0000049397184891\n",
      "GD iter. 15/99: loss=4.4724419711918895, w0=0.9998859008146385, w1=1.0000052684656446\n",
      "GD iter. 16/99: loss=4.472371427916732, w0=0.9998787679056128, w1=1.0000055971418615\n",
      "GD iter. 17/99: loss=4.472300882127611, w0=0.9998716347953815, w1=1.0000059257471379\n",
      "GD iter. 18/99: loss=4.472230333844293, w0=0.9998645014839388, w1=1.0000062542814714\n",
      "GD iter. 19/99: loss=4.472159783058062, w0=0.9998573679712786, w1=1.0000065827448599\n",
      "GD iter. 20/99: loss=4.472089229778491, w0=0.9998502342573947, w1=1.0000069111373013\n",
      "GD iter. 21/99: loss=4.472018673983169, w0=0.9998431003422814, w1=1.0000072394587933\n",
      "GD iter. 22/99: loss=4.471948115684833, w0=0.9998359662259325, w1=1.000007567709334\n",
      "GD iter. 23/99: loss=4.471877554894618, w0=0.999828831908342, w1=1.0000078958889211\n",
      "GD iter. 24/99: loss=4.4718069916052245, w0=0.999821697389504, w1=1.0000082239975525\n",
      "GD iter. 25/99: loss=4.471736425807082, w0=0.9998145626694124, w1=1.000008552035226\n",
      "GD iter. 26/99: loss=4.471665857498241, w0=0.9998074277480611, w1=1.0000088800019393\n",
      "GD iter. 27/99: loss=4.471595286695525, w0=0.9998002926254442, w1=1.0000092078976905\n",
      "GD iter. 28/99: loss=4.471524713396714, w0=0.9997931573015557, w1=1.0000095357224774\n",
      "GD iter. 29/99: loss=4.471454137596883, w0=0.9997860217763896, w1=1.0000098634762977\n",
      "GD iter. 30/99: loss=4.471383559285268, w0=0.9997788860499399, w1=1.0000101911591495\n",
      "GD iter. 31/99: loss=4.471312978477732, w0=0.9997717501222005, w1=1.0000105187710304\n",
      "GD iter. 32/99: loss=4.471242395167374, w0=0.9997646139931654, w1=1.0000108463119384\n",
      "GD iter. 33/99: loss=4.471171809356841, w0=0.9997574776628286, w1=1.0000111737818713\n",
      "GD iter. 34/99: loss=4.471101221033295, w0=0.9997503411311842, w1=1.0000115011808268\n",
      "GD iter. 35/99: loss=4.471030630222446, w0=0.9997432043982261, w1=1.000011828508803\n",
      "GD iter. 36/99: loss=4.470960036910752, w0=0.9997360674639482, w1=1.0000121557657977\n",
      "GD iter. 37/99: loss=4.470889441092447, w0=0.9997289303283445, w1=1.0000124829518087\n",
      "GD iter. 38/99: loss=4.470818842765391, w0=0.9997217929914092, w1=1.0000128100668337\n",
      "GD iter. 39/99: loss=4.470748241946, w0=0.9997146554531361, w1=1.0000131371108707\n",
      "GD iter. 40/99: loss=4.470677638616702, w0=0.9997075177135192, w1=1.0000134640839173\n",
      "GD iter. 41/99: loss=4.470607032794056, w0=0.9997003797725524, w1=1.0000137909859717\n",
      "GD iter. 42/99: loss=4.470536424472562, w0=0.99969324163023, w1=1.0000141178170316\n",
      "GD iter. 43/99: loss=4.470465813645299, w0=0.9996861032865456, w1=1.0000144445770949\n",
      "GD iter. 44/99: loss=4.470395200312737, w0=0.9996789647414934, w1=1.0000147712661593\n",
      "GD iter. 45/99: loss=4.470324584483319, w0=0.9996718259950674, w1=1.0000150978842228\n",
      "GD iter. 46/99: loss=4.470253966148205, w0=0.9996646870472615, w1=1.000015424431283\n",
      "GD iter. 47/99: loss=4.470183345321454, w0=0.9996575478980697, w1=1.0000157509073382\n",
      "GD iter. 48/99: loss=4.470112721984861, w0=0.999650408547486, w1=1.0000160773123858\n",
      "GD iter. 49/99: loss=4.470042096156263, w0=0.9996432689955044, w1=1.0000164036464239\n",
      "GD iter. 50/99: loss=4.469971467821892, w0=0.9996361292421189, w1=1.00001672990945\n",
      "GD iter. 51/99: loss=4.469900836979426, w0=0.9996289892873234, w1=1.0000170561014623\n",
      "GD iter. 52/99: loss=4.469830203649356, w0=0.9996218491311119, w1=1.0000173822224585\n",
      "GD iter. 53/99: loss=4.469759567811845, w0=0.9996147087734784, w1=1.0000177082724364\n",
      "GD iter. 54/99: loss=4.469688929471095, w0=0.9996075682144169, w1=1.000018034251394\n",
      "GD iter. 55/99: loss=4.4696182886336135, w0=0.9996004274539213, w1=1.000018360159329\n",
      "GD iter. 56/99: loss=4.46954764529927, w0=0.9995932864919856, w1=1.0000186859962394\n",
      "GD iter. 57/99: loss=4.4694769994584505, w0=0.9995861453286039, w1=1.000019011762123\n",
      "GD iter. 58/99: loss=4.469406351110875, w0=0.9995790039637701, w1=1.0000193374569775\n",
      "GD iter. 59/99: loss=4.469335700271428, w0=0.9995718623974782, w1=1.0000196630808007\n",
      "GD iter. 60/99: loss=4.469265046931174, w0=0.9995647206297221, w1=1.0000199886335908\n",
      "GD iter. 61/99: loss=4.469194391083165, w0=0.9995575786604959, w1=1.0000203141153452\n",
      "GD iter. 62/99: loss=4.46912373273421, w0=0.9995504364897935, w1=1.000020639526062\n",
      "GD iter. 63/99: loss=4.469053071901765, w0=0.9995432941176089, w1=1.000020964865739\n",
      "GD iter. 64/99: loss=4.468982408551809, w0=0.999536151543936, w1=1.0000212901343741\n",
      "GD iter. 65/99: loss=4.468911742709233, w0=0.9995290087687689, w1=1.000021615331965\n",
      "GD iter. 66/99: loss=4.468841074361551, w0=0.9995218657921016, w1=1.0000219404585096\n",
      "GD iter. 67/99: loss=4.468770403520102, w0=0.9995147226139278, w1=1.0000222655140059\n",
      "GD iter. 68/99: loss=4.468699730176156, w0=0.9995075792342418, w1=1.0000225904984514\n",
      "GD iter. 69/99: loss=4.46862905432423, w0=0.9995004356530375, w1=1.0000229154118443\n",
      "GD iter. 70/99: loss=4.468558375979142, w0=0.9994932918703087, w1=1.0000232402541822\n",
      "GD iter. 71/99: loss=4.468487695138401, w0=0.9994861478860495, w1=1.0000235650254632\n",
      "GD iter. 72/99: loss=4.468417011788138, w0=0.9994790037002539, w1=1.0000238897256848\n",
      "GD iter. 73/99: loss=4.468346325941733, w0=0.9994718593129158, w1=1.000024214354845\n",
      "GD iter. 74/99: loss=4.468275637597301, w0=0.9994647147240293, w1=1.0000245389129416\n",
      "GD iter. 75/99: loss=4.468204946749449, w0=0.9994575699335883, w1=1.0000248633999727\n",
      "GD iter. 76/99: loss=4.468134253403629, w0=0.9994504249415866, w1=1.0000251878159356\n",
      "GD iter. 77/99: loss=4.468063557554053, w0=0.9994432797480185, w1=1.0000255121608286\n",
      "GD iter. 78/99: loss=4.467992859204459, w0=0.9994361343528778, w1=1.0000258364346495\n",
      "GD iter. 79/99: loss=4.467922158363703, w0=0.9994289887561585, w1=1.000026160637396\n",
      "GD iter. 80/99: loss=4.467851455016685, w0=0.9994218429578545, w1=1.0000264847690659\n",
      "GD iter. 81/99: loss=4.467780749176117, w0=0.9994146969579599, w1=1.000026808829657\n",
      "GD iter. 82/99: loss=4.467710040829026, w0=0.9994075507564686, w1=1.0000271328191677\n",
      "GD iter. 83/99: loss=4.467639329981619, w0=0.9994004043533745, w1=1.000027456737595\n",
      "GD iter. 84/99: loss=4.467568616633917, w0=0.9993932577486717, w1=1.0000277805849374\n",
      "GD iter. 85/99: loss=4.467497900793968, w0=0.9993861109423541, w1=1.0000281043611923\n",
      "GD iter. 86/99: loss=4.467427182444737, w0=0.9993789639344156, w1=1.0000284280663578\n",
      "GD iter. 87/99: loss=4.467356461609192, w0=0.9993718167248503, w1=1.0000287517004316\n",
      "GD iter. 88/99: loss=4.467285738267874, w0=0.9993646693136521, w1=1.0000290752634116\n",
      "GD iter. 89/99: loss=4.4672150124158305, w0=0.999357521700815, w1=1.0000293987552955\n",
      "GD iter. 90/99: loss=4.467144284080653, w0=0.999350373886333, w1=1.0000297221760814\n",
      "GD iter. 91/99: loss=4.467073553244543, w0=0.9993432258702, w1=1.0000300455257671\n",
      "GD iter. 92/99: loss=4.467002819896437, w0=0.99933607765241, w1=1.0000303688043504\n",
      "GD iter. 93/99: loss=4.466932084053492, w0=0.9993289292329569, w1=1.000030692011829\n",
      "GD iter. 94/99: loss=4.466861345722194, w0=0.9993217806118347, w1=1.0000310151482006\n",
      "GD iter. 95/99: loss=4.466790604885725, w0=0.9993146317890375, w1=1.0000313382134633\n",
      "GD iter. 96/99: loss=4.466719861548847, w0=0.999307482764559, w1=1.000031661207615\n",
      "GD iter. 97/99: loss=4.466649115705459, w0=0.9993003335383935, w1=1.0000319841306535\n",
      "GD iter. 98/99: loss=4.466578367380476, w0=0.9992931841105348, w1=1.0000323069825765\n",
      "GD iter. 99/99: loss=4.466507616545441, w0=0.9992860344809767, w1=1.000032629763382\n",
      "0.60064\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.472119047951456, w0=0.9999928339031561, w1=1.0000003960912212\n",
      "GD iter. 1/99: loss=4.4720485970206205, w0=0.9999856676051798, w1=1.0000007921117062\n",
      "GD iter. 2/99: loss=4.471978143575603, w0=0.9999785011060652, w1=1.0000011880614528\n",
      "GD iter. 3/99: loss=4.471907687628405, w0=0.9999713344058062, w1=1.0000015839404588\n",
      "GD iter. 4/99: loss=4.471837229188869, w0=0.9999641675043968, w1=1.000001979748722\n",
      "GD iter. 5/99: loss=4.47176676822597, w0=0.9999570004018309, w1=1.0000023754862406\n",
      "GD iter. 6/99: loss=4.471696304779075, w0=0.9999498330981025, w1=1.000002771153012\n",
      "GD iter. 7/99: loss=4.4716258388134005, w0=0.9999426655932055, w1=1.0000031667490341\n",
      "GD iter. 8/99: loss=4.47155537035781, w0=0.9999354978871341, w1=1.0000035622743049\n",
      "GD iter. 9/99: loss=4.471484899394369, w0=0.9999283299798821, w1=1.000003957728822\n",
      "GD iter. 10/99: loss=4.471414425933806, w0=0.9999211618714435, w1=1.0000043531125835\n",
      "GD iter. 11/99: loss=4.471343949959991, w0=0.9999139935618122, w1=1.000004748425587\n",
      "GD iter. 12/99: loss=4.471273471493866, w0=0.9999068250509823, w1=1.0000051436678303\n",
      "GD iter. 13/99: loss=4.47120299053007, w0=0.9998996563389476, w1=1.0000055388393114\n",
      "GD iter. 14/99: loss=4.471132507047482, w0=0.9998924874257021, w1=1.0000059339400282\n",
      "GD iter. 15/99: loss=4.471062021072448, w0=0.9998853183112398, w1=1.0000063289699783\n",
      "GD iter. 16/99: loss=4.470991532594872, w0=0.9998781489955547, w1=1.0000067239291597\n",
      "GD iter. 17/99: loss=4.470921041600508, w0=0.9998709794786408, w1=1.00000711881757\n",
      "GD iter. 18/99: loss=4.470850548119575, w0=0.9998638097604919, w1=1.0000075136352073\n",
      "GD iter. 19/99: loss=4.470780052132724, w0=0.9998566398411022, w1=1.0000079083820692\n",
      "GD iter. 20/99: loss=4.470709553647576, w0=0.9998494697204654, w1=1.0000083030581537\n",
      "GD iter. 21/99: loss=4.470639052652241, w0=0.9998422993985756, w1=1.0000086976634586\n",
      "GD iter. 22/99: loss=4.470568549161221, w0=0.9998351288754267, w1=1.0000090921979816\n",
      "GD iter. 23/99: loss=4.47049804316473, w0=0.9998279581510128, w1=1.0000094866617206\n",
      "GD iter. 24/99: loss=4.470427534672814, w0=0.9998207872253276, w1=1.0000098810546734\n",
      "GD iter. 25/99: loss=4.47035702366942, w0=0.9998136160983654, w1=1.0000102753768378\n",
      "GD iter. 26/99: loss=4.470286510170808, w0=0.9998064447701199, w1=1.0000106696282118\n",
      "GD iter. 27/99: loss=4.470215994169143, w0=0.9997992732405852, w1=1.0000110638087931\n",
      "GD iter. 28/99: loss=4.47014547566156, w0=0.9997921015097552, w1=1.0000114579185795\n",
      "GD iter. 29/99: loss=4.470074954660636, w0=0.9997849295776238, w1=1.000011851957569\n",
      "GD iter. 30/99: loss=4.470004431149017, w0=0.9997777574441851, w1=1.000012245925759\n",
      "GD iter. 31/99: loss=4.469933905138949, w0=0.999770585109433, w1=1.0000126398231477\n",
      "GD iter. 32/99: loss=4.469863376627227, w0=0.9997634125733613, w1=1.0000130336497328\n",
      "GD iter. 33/99: loss=4.4697928456189855, w0=0.9997562398359642, w1=1.0000134274055121\n",
      "GD iter. 34/99: loss=4.469722312098979, w0=0.9997490668972355, w1=1.0000138210904836\n",
      "GD iter. 35/99: loss=4.469651776085184, w0=0.9997418937571693, w1=1.0000142147046451\n",
      "GD iter. 36/99: loss=4.469581237567485, w0=0.9997347204157594, w1=1.0000146082479942\n",
      "GD iter. 37/99: loss=4.4695106965476805, w0=0.9997275468729998, w1=1.0000150017205287\n",
      "GD iter. 38/99: loss=4.469440153028823, w0=0.9997203731288845, w1=1.0000153951222468\n",
      "GD iter. 39/99: loss=4.469369606997051, w0=0.9997131991834075, w1=1.000015788453146\n",
      "GD iter. 40/99: loss=4.469299058477645, w0=0.9997060250365627, w1=1.0000161817132243\n",
      "GD iter. 41/99: loss=4.469228507449996, w0=0.999698850688344, w1=1.0000165749024794\n",
      "GD iter. 42/99: loss=4.4691579539262785, w0=0.9996916761387454, w1=1.0000169680209092\n",
      "GD iter. 43/99: loss=4.469087397895254, w0=0.9996845013877609, w1=1.0000173610685115\n",
      "GD iter. 44/99: loss=4.469016839370355, w0=0.9996773264353844, w1=1.0000177540452841\n",
      "GD iter. 45/99: loss=4.468946278335868, w0=0.9996701512816099, w1=1.0000181469512248\n",
      "GD iter. 46/99: loss=4.468875714807323, w0=0.9996629759264313, w1=1.0000185397863315\n",
      "GD iter. 47/99: loss=4.468805148774225, w0=0.9996558003698425, w1=1.000018932550602\n",
      "GD iter. 48/99: loss=4.468734580239913, w0=0.9996486246118376, w1=1.000019325244034\n",
      "GD iter. 49/99: loss=4.468664009205338, w0=0.9996414486524104, w1=1.0000197178666255\n",
      "GD iter. 50/99: loss=4.468593435669915, w0=0.999634272491555, w1=1.0000201104183741\n",
      "GD iter. 51/99: loss=4.468522859627975, w0=0.9996270961292653, w1=1.000020502899278\n",
      "GD iter. 52/99: loss=4.468452281090411, w0=0.9996199195655352, w1=1.0000208953093346\n",
      "GD iter. 53/99: loss=4.468381700055254, w0=0.9996127428003587, w1=1.000021287648542\n",
      "GD iter. 54/99: loss=4.468311116513669, w0=0.9996055658337297, w1=1.000021679916898\n",
      "GD iter. 55/99: loss=4.468240530480162, w0=0.9995983886656422, w1=1.0000220721144002\n",
      "GD iter. 56/99: loss=4.468169941932499, w0=0.9995912112960902, w1=1.0000224642410467\n",
      "GD iter. 57/99: loss=4.468099350895717, w0=0.9995840337250675, w1=1.0000228562968352\n",
      "GD iter. 58/99: loss=4.46802875735294, w0=0.9995768559525682, w1=1.0000232482817635\n",
      "GD iter. 59/99: loss=4.46795816130699, w0=0.9995696779785861, w1=1.0000236401958293\n",
      "GD iter. 60/99: loss=4.467887562763049, w0=0.9995624998031153, w1=1.0000240320390308\n",
      "GD iter. 61/99: loss=4.467816961721531, w0=0.9995553214261497, w1=1.0000244238113656\n",
      "GD iter. 62/99: loss=4.4677463581755905, w0=0.9995481428476831, w1=1.0000248155128315\n",
      "GD iter. 63/99: loss=4.467675752131069, w0=0.9995409640677096, w1=1.0000252071434264\n",
      "GD iter. 64/99: loss=4.46760514358147, w0=0.9995337850862233, w1=1.0000255987031479\n",
      "GD iter. 65/99: loss=4.467534532539306, w0=0.9995266059032178, w1=1.000025990191994\n",
      "GD iter. 66/99: loss=4.467463918984921, w0=0.9995194265186873, w1=1.0000263816099624\n",
      "GD iter. 67/99: loss=4.467393302938797, w0=0.9995122469326256, w1=1.0000267729570511\n",
      "GD iter. 68/99: loss=4.467322684394592, w0=0.9995050671450267, w1=1.0000271642332579\n",
      "GD iter. 69/99: loss=4.467252063349349, w0=0.9994978871558846, w1=1.0000275554385805\n",
      "GD iter. 70/99: loss=4.4671814398077725, w0=0.9994907069651932, w1=1.0000279465730166\n",
      "GD iter. 71/99: loss=4.467110813752838, w0=0.9994835265729464, w1=1.0000283376365644\n",
      "GD iter. 72/99: loss=4.467040185203991, w0=0.9994763459791381, w1=1.0000287286292213\n",
      "GD iter. 73/99: loss=4.466969554161352, w0=0.9994691651837625, w1=1.0000291195509854\n",
      "GD iter. 74/99: loss=4.466898920609831, w0=0.9994619841868133, w1=1.0000295104018544\n",
      "GD iter. 75/99: loss=4.466828284558759, w0=0.9994548029882846, w1=1.000029901181826\n",
      "GD iter. 76/99: loss=4.466757646012451, w0=0.9994476215881702, w1=1.0000302918908985\n",
      "GD iter. 77/99: loss=4.466687004959291, w0=0.9994404399864641, w1=1.0000306825290692\n",
      "GD iter. 78/99: loss=4.466616361412124, w0=0.9994332581831603, w1=1.0000310730963362\n",
      "GD iter. 79/99: loss=4.466545715374052, w0=0.9994260761782526, w1=1.0000314635926972\n",
      "GD iter. 80/99: loss=4.466475066823427, w0=0.9994188939717351, w1=1.00003185401815\n",
      "GD iter. 81/99: loss=4.466404415773266, w0=0.9994117115636016, w1=1.0000322443726926\n",
      "GD iter. 82/99: loss=4.466333762226657, w0=0.9994045289538462, w1=1.0000326346563226\n",
      "GD iter. 83/99: loss=4.46626310617583, w0=0.9993973461424628, w1=1.000033024869038\n",
      "GD iter. 84/99: loss=4.466192447628067, w0=0.9993901631294452, w1=1.0000334150108363\n",
      "GD iter. 85/99: loss=4.46612178658972, w0=0.9993829799147874, w1=1.0000338050817157\n",
      "GD iter. 86/99: loss=4.4660511230355215, w0=0.9993757964984834, w1=1.0000341950816738\n",
      "GD iter. 87/99: loss=4.465980456993057, w0=0.9993686128805271, w1=1.0000345850107084\n",
      "GD iter. 88/99: loss=4.465909788446753, w0=0.9993614290609125, w1=1.0000349748688175\n",
      "GD iter. 89/99: loss=4.4658391173970164, w0=0.9993542450396335, w1=1.0000353646559987\n",
      "GD iter. 90/99: loss=4.465768443861946, w0=0.999347060816684, w1=1.00003575437225\n",
      "GD iter. 91/99: loss=4.465697767815484, w0=0.999339876392058, w1=1.0000361440175691\n",
      "GD iter. 92/99: loss=4.465627089275119, w0=0.9993326917657493, w1=1.0000365335919539\n",
      "GD iter. 93/99: loss=4.465556408225352, w0=0.999325506937752, w1=1.000036923095402\n",
      "GD iter. 94/99: loss=4.4654857246900574, w0=0.99931832190806, w1=1.0000373125279116\n",
      "GD iter. 95/99: loss=4.465415038648644, w0=0.9993111366766673, w1=1.0000377018894802\n",
      "GD iter. 96/99: loss=4.465344350102103, w0=0.9993039512435676, w1=1.0000380911801057\n",
      "GD iter. 97/99: loss=4.465273659068087, w0=0.9992967656087551, w1=1.000038480399786\n",
      "GD iter. 98/99: loss=4.465202965527661, w0=0.9992895797722237, w1=1.0000388695485187\n",
      "GD iter. 99/99: loss=4.465132269493662, w0=0.9992823937339671, w1=1.0000392586263018\n",
      "0.60328\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.470168269670574, w0=0.9999928000632039, w1=1.0000003620911022\n",
      "GD iter. 1/99: loss=4.4700978518543675, w0=0.999985599925994, w1=1.0000007241126891\n",
      "GD iter. 2/99: loss=4.470027431539622, w0=0.9999783995883644, w1=1.0000010860647586\n",
      "GD iter. 3/99: loss=4.469957008704041, w0=0.9999711990503092, w1=1.0000014479473087\n",
      "GD iter. 4/99: loss=4.469886583384594, w0=0.9999639983118223, w1=1.0000018097603371\n",
      "GD iter. 5/99: loss=4.469816155560688, w0=0.9999567973728978, w1=1.000002171503842\n",
      "GD iter. 6/99: loss=4.469745725227242, w0=0.9999495962335299, w1=1.0000025331778215\n",
      "GD iter. 7/99: loss=4.469675292395561, w0=0.9999423948937124, w1=1.0000028947822732\n",
      "GD iter. 8/99: loss=4.469604857069491, w0=0.9999351933534395, w1=1.0000032563171952\n",
      "GD iter. 9/99: loss=4.469534419240458, w0=0.9999279916127053, w1=1.0000036177825853\n",
      "GD iter. 10/99: loss=4.469463978903689, w0=0.9999207896715038, w1=1.0000039791784416\n",
      "GD iter. 11/99: loss=4.469393536069605, w0=0.999913587529829, w1=1.000004340504762\n",
      "GD iter. 12/99: loss=4.469323090738493, w0=0.9999063851876748, w1=1.0000047017615445\n",
      "GD iter. 13/99: loss=4.469252642905281, w0=0.9998991826450355, w1=1.0000050629487869\n",
      "GD iter. 14/99: loss=4.4691821925691615, w0=0.9998919799019051, w1=1.000005424066487\n",
      "GD iter. 15/99: loss=4.469111739723009, w0=0.9998847769582776, w1=1.000005785114643\n",
      "GD iter. 16/99: loss=4.46904128438062, w0=0.999877573814147, w1=1.000006146093253\n",
      "GD iter. 17/99: loss=4.468970826547452, w0=0.9998703704695074, w1=1.0000065070023147\n",
      "GD iter. 18/99: loss=4.468900366199928, w0=0.9998631669243528, w1=1.0000068678418261\n",
      "GD iter. 19/99: loss=4.46882990335742, w0=0.9998559631786774, w1=1.0000072286117851\n",
      "GD iter. 20/99: loss=4.468759438020087, w0=0.9998487592324751, w1=1.0000075893121896\n",
      "GD iter. 21/99: loss=4.46868897016652, w0=0.9998415550857399, w1=1.0000079499430377\n",
      "GD iter. 22/99: loss=4.4686184998211225, w0=0.9998343507384659, w1=1.0000083105043271\n",
      "GD iter. 23/99: loss=4.468548026969814, w0=0.9998271461906472, w1=1.000008670996056\n",
      "GD iter. 24/99: loss=4.468477551633666, w0=0.9998199414422777, w1=1.0000090314182222\n",
      "GD iter. 25/99: loss=4.46840707378113, w0=0.9998127364933516, w1=1.0000093917708235\n",
      "GD iter. 26/99: loss=4.468336593431433, w0=0.9998055313438629, w1=1.000009752053858\n",
      "GD iter. 27/99: loss=4.4682661105817125, w0=0.9997983259938056, w1=1.0000101122673237\n",
      "GD iter. 28/99: loss=4.46819562523291, w0=0.9997911204431738, w1=1.0000104724112184\n",
      "GD iter. 29/99: loss=4.468125137391862, w0=0.9997839146919614, w1=1.0000108324855403\n",
      "GD iter. 30/99: loss=4.468054647033362, w0=0.9997767087401626, w1=1.0000111924902872\n",
      "GD iter. 31/99: loss=4.467984154180577, w0=0.9997695025877713, w1=1.000011552425457\n",
      "GD iter. 32/99: loss=4.467913658829803, w0=0.9997622962347817, w1=1.0000119122910474\n",
      "GD iter. 33/99: loss=4.467843160984211, w0=0.9997550896811878, w1=1.0000122720870566\n",
      "GD iter. 34/99: loss=4.467772660621395, w0=0.9997478829269835, w1=1.0000126318134825\n",
      "GD iter. 35/99: loss=4.467702157772815, w0=0.999740675972163, w1=1.0000129914703233\n",
      "GD iter. 36/99: loss=4.467631652418653, w0=0.9997334688167202, w1=1.0000133510575766\n",
      "GD iter. 37/99: loss=4.467561144567448, w0=0.9997262614606492, w1=1.0000137105752405\n",
      "GD iter. 38/99: loss=4.467490634215965, w0=0.9997190539039442, w1=1.0000140700233127\n",
      "GD iter. 39/99: loss=4.467420121352868, w0=0.999711846146599, w1=1.0000144294017914\n",
      "GD iter. 40/99: loss=4.467349606003365, w0=0.9997046381886078, w1=1.0000147887106745\n",
      "GD iter. 41/99: loss=4.4672790881525195, w0=0.9996974300299645, w1=1.0000151479499597\n",
      "GD iter. 42/99: loss=4.467208567793478, w0=0.9996902216706632, w1=1.0000155071196453\n",
      "GD iter. 43/99: loss=4.467138044936927, w0=0.999683013110698, w1=1.000015866219729\n",
      "GD iter. 44/99: loss=4.4670675195830984, w0=0.9996758043500628, w1=1.0000162252502087\n",
      "GD iter. 45/99: loss=4.466996991734144, w0=0.9996685953887516, w1=1.0000165842110826\n",
      "GD iter. 46/99: loss=4.466926461376511, w0=0.9996613862267587, w1=1.0000169431023485\n",
      "GD iter. 47/99: loss=4.466855928525175, w0=0.999654176864078, w1=1.0000173019240042\n",
      "GD iter. 48/99: loss=4.466785393162987, w0=0.9996469673007035, w1=1.0000176606760478\n",
      "GD iter. 49/99: loss=4.466714855315332, w0=0.9996397575366291, w1=1.0000180193584771\n",
      "GD iter. 50/99: loss=4.466644314955445, w0=0.9996325475718492, w1=1.0000183779712901\n",
      "GD iter. 51/99: loss=4.466573772106507, w0=0.9996253374063575, w1=1.0000187365144848\n",
      "GD iter. 52/99: loss=4.466503226754914, w0=0.9996181270401482, w1=1.0000190949880592\n",
      "GD iter. 53/99: loss=4.466432678900921, w0=0.9996109164732152, w1=1.000019453392011\n",
      "GD iter. 54/99: loss=4.466362128539965, w0=0.9996037057055527, w1=1.0000198117263384\n",
      "GD iter. 55/99: loss=4.466291575691034, w0=0.9995964947371545, w1=1.000020169991039\n",
      "GD iter. 56/99: loss=4.4662210203443795, w0=0.9995892835680149, w1=1.000020528186111\n",
      "GD iter. 57/99: loss=4.4661504624951, w0=0.9995820721981278, w1=1.0000208863115523\n",
      "GD iter. 58/99: loss=4.466079902141488, w0=0.9995748606274871, w1=1.0000212443673608\n",
      "GD iter. 59/99: loss=4.466009339293293, w0=0.9995676488560871, w1=1.0000216023535344\n",
      "GD iter. 60/99: loss=4.465938773941912, w0=0.9995604368839216, w1=1.000021960270071\n",
      "GD iter. 61/99: loss=4.465868206095922, w0=0.9995532247109848, w1=1.0000223181169687\n",
      "GD iter. 62/99: loss=4.46579763575131, w0=0.9995460123372707, w1=1.0000226758942254\n",
      "GD iter. 63/99: loss=4.465727062906396, w0=0.9995387997627733, w1=1.000023033601839\n",
      "GD iter. 64/99: loss=4.46565648755522, w0=0.9995315869874866, w1=1.0000233912398073\n",
      "GD iter. 65/99: loss=4.465585909709778, w0=0.9995243740114046, w1=1.0000237488081285\n",
      "GD iter. 66/99: loss=4.465515329358517, w0=0.9995171608345214, w1=1.0000241063068003\n",
      "GD iter. 67/99: loss=4.46544474652046, w0=0.999509947456831, w1=1.0000244637358207\n",
      "GD iter. 68/99: loss=4.465374161176296, w0=0.9995027338783274, w1=1.0000248210951876\n",
      "GD iter. 69/99: loss=4.465303573335705, w0=0.9994955200990048, w1=1.000025178384899\n",
      "GD iter. 70/99: loss=4.465232982995694, w0=0.999488306118857, w1=1.000025535604953\n",
      "GD iter. 71/99: loss=4.465162390155385, w0=0.999481091937878, w1=1.0000258927553471\n",
      "GD iter. 72/99: loss=4.4650917948105056, w0=0.9994738775560621, w1=1.0000262498360797\n",
      "GD iter. 73/99: loss=4.46502119698057, w0=0.999466662973403, w1=1.0000266068471484\n",
      "GD iter. 74/99: loss=4.464950596644461, w0=0.999459448189895, w1=1.0000269637885513\n",
      "GD iter. 75/99: loss=4.464879993806015, w0=0.999452233205532, w1=1.0000273206602863\n",
      "GD iter. 76/99: loss=4.464809388470303, w0=0.999445018020308, w1=1.0000276774623513\n",
      "GD iter. 77/99: loss=4.464738780634925, w0=0.9994378026342171, w1=1.0000280341947443\n",
      "GD iter. 78/99: loss=4.464668170303319, w0=0.9994305870472533, w1=1.0000283908574632\n",
      "GD iter. 79/99: loss=4.464597557475621, w0=0.9994233712594106, w1=1.0000287474505059\n",
      "GD iter. 80/99: loss=4.464526942144543, w0=0.9994161552706831, w1=1.0000291039738702\n",
      "GD iter. 81/99: loss=4.4644563243189435, w0=0.9994089390810647, w1=1.0000294604275544\n",
      "GD iter. 82/99: loss=4.464385703996096, w0=0.9994017226905495, w1=1.000029816811556\n",
      "GD iter. 83/99: loss=4.464315081163637, w0=0.9993945060991315, w1=1.0000301731258734\n",
      "GD iter. 84/99: loss=4.464244455841901, w0=0.9993872893068048, w1=1.000030529370504\n",
      "GD iter. 85/99: loss=4.464173828020118, w0=0.9993800723135633, w1=1.0000308855454463\n",
      "GD iter. 86/99: loss=4.464103197697437, w0=0.9993728551194011, w1=1.0000312416506978\n",
      "GD iter. 87/99: loss=4.464032564880131, w0=0.9993656377243122, w1=1.0000315976862566\n",
      "GD iter. 88/99: loss=4.463961929568975, w0=0.9993584201282906, w1=1.0000319536521205\n",
      "GD iter. 89/99: loss=4.4638912917490625, w0=0.9993512023313303, w1=1.0000323095482877\n",
      "GD iter. 90/99: loss=4.463820651434412, w0=0.9993439843334254, w1=1.000032665374756\n",
      "GD iter. 91/99: loss=4.463750008621159, w0=0.9993367661345699, w1=1.0000330211315231\n",
      "GD iter. 92/99: loss=4.463679363311625, w0=0.9993295477347578, w1=1.0000333768185874\n",
      "GD iter. 93/99: loss=4.463608715502158, w0=0.9993223291339831, w1=1.0000337324359465\n",
      "GD iter. 94/99: loss=4.463538065205097, w0=0.9993151103322399, w1=1.0000340879835983\n",
      "GD iter. 95/99: loss=4.463467412393474, w0=0.999307891329522, w1=1.000034443461541\n",
      "GD iter. 96/99: loss=4.463396757095234, w0=0.9993006721258237, w1=1.0000347988697722\n",
      "GD iter. 97/99: loss=4.463326099291551, w0=0.9992934527211389, w1=1.00003515420829\n",
      "GD iter. 98/99: loss=4.463255438988505, w0=0.9992862331154616, w1=1.0000355094770923\n",
      "GD iter. 99/99: loss=4.463184776201813, w0=0.9992790133087859, w1=1.000035864676177\n",
      "0.59824\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.482669768390976, w0=0.9999927372545427, w1=1.0000003522491032\n",
      "GD iter. 1/99: loss=4.482599114900274, w0=0.9999854743083411, w1=1.0000007044275534\n",
      "GD iter. 2/99: loss=4.482528458898277, w0=0.9999782111613889, w1=1.0000010565353485\n",
      "GD iter. 3/99: loss=4.482457800387185, w0=0.99997094781368, w1=1.0000014085724862\n",
      "GD iter. 4/99: loss=4.482387139364463, w0=0.9999636842652087, w1=1.0000017605389644\n",
      "GD iter. 5/99: loss=4.482316475827624, w0=0.9999564205159686, w1=1.0000021124347809\n",
      "GD iter. 6/99: loss=4.482245809774957, w0=0.9999491565659538, w1=1.0000024642599337\n",
      "GD iter. 7/99: loss=4.482175141213825, w0=0.9999418924151584, w1=1.0000028160144205\n",
      "GD iter. 8/99: loss=4.482104470150604, w0=0.9999346280635761, w1=1.0000031676982393\n",
      "GD iter. 9/99: loss=4.482033796557483, w0=0.999927363511201, w1=1.0000035193113876\n",
      "GD iter. 10/99: loss=4.481963120460394, w0=0.9999200987580271, w1=1.0000038708538637\n",
      "GD iter. 11/99: loss=4.481892441853961, w0=0.9999128338040483, w1=1.000004222325665\n",
      "GD iter. 12/99: loss=4.481821760738684, w0=0.9999055686492584, w1=1.0000045737267897\n",
      "GD iter. 13/99: loss=4.481751077104518, w0=0.9998983032936516, w1=1.0000049250572356\n",
      "GD iter. 14/99: loss=4.481680390966761, w0=0.9998910377372218, w1=1.0000052763170004\n",
      "GD iter. 15/99: loss=4.481609702305406, w0=0.9998837719799628, w1=1.000005627506082\n",
      "GD iter. 16/99: loss=4.481539011131713, w0=0.9998765060218687, w1=1.0000059786244782\n",
      "GD iter. 17/99: loss=4.481468317456273, w0=0.9998692398629334, w1=1.0000063296721868\n",
      "GD iter. 18/99: loss=4.481397621262442, w0=0.9998619735031509, w1=1.0000066806492058\n",
      "GD iter. 19/99: loss=4.48132692255866, w0=0.999854706942515, w1=1.000007031555533\n",
      "GD iter. 20/99: loss=4.481256221352316, w0=0.9998474401810198, w1=1.0000073823911662\n",
      "GD iter. 21/99: loss=4.481185517619628, w0=0.9998401732186593, w1=1.0000077331561033\n",
      "GD iter. 22/99: loss=4.4811148113824215, w0=0.9998329060554273, w1=1.000008083850342\n",
      "GD iter. 23/99: loss=4.481044102638411, w0=0.9998256386913178, w1=1.0000084344738804\n",
      "GD iter. 24/99: loss=4.48097339138369, w0=0.9998183711263249, w1=1.000008785026716\n",
      "GD iter. 25/99: loss=4.480902677602844, w0=0.9998111033604423, w1=1.000009135508847\n",
      "GD iter. 26/99: loss=4.480831961324657, w0=0.9998038353936641, w1=1.000009485920271\n",
      "GD iter. 27/99: loss=4.48076124253545, w0=0.9997965672259843, w1=1.000009836260986\n",
      "GD iter. 28/99: loss=4.480690521221815, w0=0.9997892988573968, w1=1.0000101865309896\n",
      "GD iter. 29/99: loss=4.480619797408747, w0=0.9997820302878954, w1=1.00001053673028\n",
      "GD iter. 30/99: loss=4.480549071085377, w0=0.9997747615174741, w1=1.0000108868588549\n",
      "GD iter. 31/99: loss=4.480478342254073, w0=0.9997674925461271, w1=1.000011236916712\n",
      "GD iter. 32/99: loss=4.480407610900522, w0=0.9997602233738481, w1=1.0000115869038493\n",
      "GD iter. 33/99: loss=4.480336877040255, w0=0.9997529540006311, w1=1.0000119368202645\n",
      "GD iter. 34/99: loss=4.480266140660168, w0=0.9997456844264702, w1=1.0000122866659555\n",
      "GD iter. 35/99: loss=4.48019540178552, w0=0.999738414651359, w1=1.0000126364409203\n",
      "GD iter. 36/99: loss=4.4801246603874985, w0=0.9997311446752918, w1=1.0000129861451565\n",
      "GD iter. 37/99: loss=4.480053916483032, w0=0.9997238744982624, w1=1.000013335778662\n",
      "GD iter. 38/99: loss=4.4799831700666966, w0=0.9997166041202648, w1=1.0000136853414348\n",
      "GD iter. 39/99: loss=4.479912421144043, w0=0.9997093335412928, w1=1.0000140348334725\n",
      "GD iter. 40/99: loss=4.47984166969989, w0=0.9997020627613404, w1=1.000014384254773\n",
      "GD iter. 41/99: loss=4.4797709157584755, w0=0.9996947917804017, w1=1.0000147336053344\n",
      "GD iter. 42/99: loss=4.479700159304606, w0=0.9996875205984704, w1=1.0000150828851544\n",
      "GD iter. 43/99: loss=4.479629400327821, w0=0.9996802492155407, w1=1.0000154320942307\n",
      "GD iter. 44/99: loss=4.479558638852725, w0=0.9996729776316063, w1=1.0000157812325612\n",
      "GD iter. 45/99: loss=4.4794878748596, w0=0.9996657058466614, w1=1.0000161303001438\n",
      "GD iter. 46/99: loss=4.479417108360635, w0=0.9996584338606997, w1=1.0000164792969763\n",
      "GD iter. 47/99: loss=4.479346339346927, w0=0.9996511616737154, w1=1.0000168282230566\n",
      "GD iter. 48/99: loss=4.479275567823897, w0=0.9996438892857021, w1=1.0000171770783826\n",
      "GD iter. 49/99: loss=4.479204793792215, w0=0.999636616696654, w1=1.000017525862952\n",
      "GD iter. 50/99: loss=4.479134017250667, w0=0.999629343906565, w1=1.0000178745767627\n",
      "GD iter. 51/99: loss=4.479063238195516, w0=0.999622070915429, w1=1.0000182232198125\n",
      "GD iter. 52/99: loss=4.47899245663761, w0=0.9996147977232399, w1=1.0000185717920993\n",
      "GD iter. 53/99: loss=4.478921672558847, w0=0.9996075243299918, w1=1.000018920293621\n",
      "GD iter. 54/99: loss=4.478850885982549, w0=0.9996002507356785, w1=1.0000192687243752\n",
      "GD iter. 55/99: loss=4.478780096884302, w0=0.999592976940294, w1=1.0000196170843598\n",
      "GD iter. 56/99: loss=4.478709305278557, w0=0.9995857029438323, w1=1.0000199653735728\n",
      "GD iter. 57/99: loss=4.478638511163329, w0=0.9995784287462872, w1=1.000020313592012\n",
      "GD iter. 58/99: loss=4.478567714539114, w0=0.9995711543476528, w1=1.0000206617396752\n",
      "GD iter. 59/99: loss=4.478496915400413, w0=0.9995638797479228, w1=1.00002100981656\n",
      "GD iter. 60/99: loss=4.478426113761666, w0=0.9995566049470913, w1=1.0000213578226647\n",
      "GD iter. 61/99: loss=4.478355309609114, w0=0.9995493299451522, w1=1.0000217057579868\n",
      "GD iter. 62/99: loss=4.47828450294511, w0=0.9995420547420996, w1=1.0000220536225244\n",
      "GD iter. 63/99: loss=4.4782136937595896, w0=0.9995347793379271, w1=1.000022401416275\n",
      "GD iter. 64/99: loss=4.47814288208785, w0=0.9995275037326289, w1=1.0000227491392368\n",
      "GD iter. 65/99: loss=4.478072067886053, w0=0.9995202279261989, w1=1.0000230967914074\n",
      "GD iter. 66/99: loss=4.478001251180091, w0=0.999512951918631, w1=1.0000234443727847\n",
      "GD iter. 67/99: loss=4.4779304319715685, w0=0.9995056757099191, w1=1.0000237918833665\n",
      "GD iter. 68/99: loss=4.477859610247553, w0=0.9994983993000572, w1=1.0000241393231508\n",
      "GD iter. 69/99: loss=4.47778878601034, w0=0.9994911226890393, w1=1.0000244866921353\n",
      "GD iter. 70/99: loss=4.477717959272457, w0=0.9994838458768591, w1=1.0000248339903177\n",
      "GD iter. 71/99: loss=4.477647130020543, w0=0.9994765688635108, w1=1.0000251812176961\n",
      "GD iter. 72/99: loss=4.477576298260405, w0=0.9994692916489881, w1=1.0000255283742683\n",
      "GD iter. 73/99: loss=4.477505463987937, w0=0.9994620142332852, w1=1.000025875460032\n",
      "GD iter. 74/99: loss=4.477434627209187, w0=0.9994547366163958, w1=1.000026222474985\n",
      "GD iter. 75/99: loss=4.477363787919314, w0=0.999447458798314, w1=1.0000265694191253\n",
      "GD iter. 76/99: loss=4.477292946116158, w0=0.9994401807790335, w1=1.0000269162924507\n",
      "GD iter. 77/99: loss=4.477222101813702, w0=0.9994329025585484, w1=1.000027263094959\n",
      "GD iter. 78/99: loss=4.477151254987998, w0=0.9994256241368528, w1=1.000027609826648\n",
      "GD iter. 79/99: loss=4.477080405662998, w0=0.9994183455139403, w1=1.0000279564875156\n",
      "GD iter. 80/99: loss=4.4770095538263215, w0=0.999411066689805, w1=1.0000283030775596\n",
      "GD iter. 81/99: loss=4.47693869947817, w0=0.9994037876644408, w1=1.0000286495967778\n",
      "GD iter. 82/99: loss=4.476867842631681, w0=0.9993965084378417, w1=1.0000289960451683\n",
      "GD iter. 83/99: loss=4.476796983260455, w0=0.9993892290100015, w1=1.0000293424227287\n",
      "GD iter. 84/99: loss=4.476726121381253, w0=0.9993819493809143, w1=1.0000296887294569\n",
      "GD iter. 85/99: loss=4.476655257002583, w0=0.9993746695505739, w1=1.0000300349653506\n",
      "GD iter. 86/99: loss=4.476584390108708, w0=0.9993673895189742, w1=1.0000303811304077\n",
      "GD iter. 87/99: loss=4.476513520710921, w0=0.9993601092861093, w1=1.000030727224626\n",
      "GD iter. 88/99: loss=4.476442648797499, w0=0.999352828851973, w1=1.0000310732480036\n",
      "GD iter. 89/99: loss=4.476371774383139, w0=0.9993455482165592, w1=1.000031419200538\n",
      "GD iter. 90/99: loss=4.476300897453899, w0=0.9993382673798619, w1=1.0000317650822272\n",
      "GD iter. 91/99: loss=4.476230018017632, w0=0.999330986341875, w1=1.000032110893069\n",
      "GD iter. 92/99: loss=4.476159136070212, w0=0.9993237051025925, w1=1.0000324566330612\n",
      "GD iter. 93/99: loss=4.4760882516168214, w0=0.9993164236620082, w1=1.0000328023022018\n",
      "GD iter. 94/99: loss=4.476017364658371, w0=0.9993091420201162, w1=1.0000331479004885\n",
      "GD iter. 95/99: loss=4.475946475190665, w0=0.9993018601769103, w1=1.0000334934279191\n",
      "GD iter. 96/99: loss=4.475875583208556, w0=0.9992945781323843, w1=1.0000338388844916\n",
      "GD iter. 97/99: loss=4.47580468871931, w0=0.9992872958865324, w1=1.0000341842702036\n",
      "GD iter. 98/99: loss=4.47573379172194, w0=0.9992800134393484, w1=1.000034529585053\n",
      "GD iter. 99/99: loss=4.4756628922217905, w0=0.9992727307908261, w1=1.0000348748290377\n",
      "0.6024\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.464248145647887, w0=0.9999928580749549, w1=1.0000003625172191\n",
      "GD iter. 1/99: loss=4.464177924643788, w0=0.9999857159497874, w1=1.0000007249643026\n",
      "GD iter. 2/99: loss=4.4641077011431065, w0=0.9999785736244916, w1=1.0000010873412482\n",
      "GD iter. 3/99: loss=4.4640374751481895, w0=0.9999714310990616, w1=1.0000014496480536\n",
      "GD iter. 4/99: loss=4.463967246666462, w0=0.9999642883734913, w1=1.000001811884717\n",
      "GD iter. 5/99: loss=4.463897015692076, w0=0.9999571454477746, w1=1.000002174051236\n",
      "GD iter. 6/99: loss=4.463826782220545, w0=0.9999500023219057, w1=1.0000025361476086\n",
      "GD iter. 7/99: loss=4.463756546268297, w0=0.9999428589958784, w1=1.0000028981738325\n",
      "GD iter. 8/99: loss=4.463686307827049, w0=0.9999357154696868, w1=1.0000032601299058\n",
      "GD iter. 9/99: loss=4.463616066882462, w0=0.999928571743325, w1=1.0000036220158262\n",
      "GD iter. 10/99: loss=4.463545823455973, w0=0.9999214278167867, w1=1.0000039838315915\n",
      "GD iter. 11/99: loss=4.463475577540174, w0=0.9999142836900662, w1=1.0000043455771996\n",
      "GD iter. 12/99: loss=4.463405329136959, w0=0.9999071393631573, w1=1.0000047072526486\n",
      "GD iter. 13/99: loss=4.463335078233278, w0=0.9998999948360542, w1=1.000005068857936\n",
      "GD iter. 14/99: loss=4.463264824848795, w0=0.9998928501087506, w1=1.00000543039306\n",
      "GD iter. 15/99: loss=4.4631945689616215, w0=0.9998857051812408, w1=1.000005791858018\n",
      "GD iter. 16/99: loss=4.463124310585711, w0=0.9998785600535185, w1=1.0000061532528084\n",
      "GD iter. 17/99: loss=4.463054049726643, w0=0.9998714147255778, w1=1.0000065145774288\n",
      "GD iter. 18/99: loss=4.462983786369299, w0=0.9998642691974129, w1=1.000006875831877\n",
      "GD iter. 19/99: loss=4.462913520530263, w0=0.9998571234690176, w1=1.0000072370161508\n",
      "GD iter. 20/99: loss=4.462843252201769, w0=0.9998499775403857, w1=1.0000075981302483\n",
      "GD iter. 21/99: loss=4.462772981374224, w0=0.9998428314115115, w1=1.0000079591741673\n",
      "GD iter. 22/99: loss=4.46270270806865, w0=0.999835685082389, w1=1.0000083201479055\n",
      "GD iter. 23/99: loss=4.462632432267087, w0=0.9998285385530119, w1=1.000008681051461\n",
      "GD iter. 24/99: loss=4.46256215397025, w0=0.9998213918233745, w1=1.0000090418848313\n",
      "GD iter. 25/99: loss=4.462491873187666, w0=0.9998142448934706, w1=1.0000094026480146\n",
      "GD iter. 26/99: loss=4.462421589912828, w0=0.9998070977632942, w1=1.0000097633410086\n",
      "GD iter. 27/99: loss=4.462351304152405, w0=0.9997999504328394, w1=1.000010123963811\n",
      "GD iter. 28/99: loss=4.462281015894498, w0=0.9997928029021002, w1=1.00001048451642\n",
      "GD iter. 29/99: loss=4.462210725160811, w0=0.9997856551710704, w1=1.0000108449988332\n",
      "GD iter. 30/99: loss=4.462140431917565, w0=0.9997785072397442, w1=1.0000112054110486\n",
      "GD iter. 31/99: loss=4.462070136198549, w0=0.9997713591081154, w1=1.000011565753064\n",
      "GD iter. 32/99: loss=4.461999837991665, w0=0.9997642107761782, w1=1.0000119260248772\n",
      "GD iter. 33/99: loss=4.46192953728138, w0=0.9997570622439264, w1=1.0000122862264862\n",
      "GD iter. 34/99: loss=4.461859234089521, w0=0.999749913511354, w1=1.000012646357889\n",
      "GD iter. 35/99: loss=4.4617889284098355, w0=0.999742764578455, w1=1.0000130064190829\n",
      "GD iter. 36/99: loss=4.461718620242074, w0=0.9997356154452235, w1=1.000013366410066\n",
      "GD iter. 37/99: loss=4.461648309581658, w0=0.9997284661116533, w1=1.0000137263308366\n",
      "GD iter. 38/99: loss=4.461577996426688, w0=0.9997213165777387, w1=1.0000140861813922\n",
      "GD iter. 39/99: loss=4.461507680789215, w0=0.9997141668434734, w1=1.0000144459617306\n",
      "GD iter. 40/99: loss=4.461437362655551, w0=0.9997070169088513, w1=1.0000148056718496\n",
      "GD iter. 41/99: loss=4.461367042040242, w0=0.9996998667738667, w1=1.0000151653117473\n",
      "GD iter. 42/99: loss=4.461296718930557, w0=0.9996927164385134, w1=1.0000155248814213\n",
      "GD iter. 43/99: loss=4.4612263933292855, w0=0.9996855659027855, w1=1.0000158843808695\n",
      "GD iter. 44/99: loss=4.461156065250814, w0=0.9996784151666768, w1=1.00001624381009\n",
      "GD iter. 45/99: loss=4.461085734667643, w0=0.9996712642301814, w1=1.0000166031690803\n",
      "GD iter. 46/99: loss=4.461015401600132, w0=0.9996641130932932, w1=1.0000169624578386\n",
      "GD iter. 47/99: loss=4.46094506604541, w0=0.9996569617560063, w1=1.0000173216763626\n",
      "GD iter. 48/99: loss=4.460874727996538, w0=0.9996498102183146, w1=1.0000176808246501\n",
      "GD iter. 49/99: loss=4.460804387463107, w0=0.999642658480212, w1=1.000018039902699\n",
      "GD iter. 50/99: loss=4.460734044442456, w0=0.9996355065416928, w1=1.0000183989105071\n",
      "GD iter. 51/99: loss=4.460663698923588, w0=0.9996283544027507, w1=1.0000187578480724\n",
      "GD iter. 52/99: loss=4.460593350925702, w0=0.9996212020633797, w1=1.0000191167153927\n",
      "GD iter. 53/99: loss=4.46052300044685, w0=0.9996140495235738, w1=1.0000194755124656\n",
      "GD iter. 54/99: loss=4.460452647452966, w0=0.999606896783327, w1=1.0000198342392894\n",
      "GD iter. 55/99: loss=4.460382291992883, w0=0.9995997438426334, w1=1.0000201928958616\n",
      "GD iter. 56/99: loss=4.4603119340383435, w0=0.9995925907014869, w1=1.0000205514821803\n",
      "GD iter. 57/99: loss=4.460241573590856, w0=0.9995854373598814, w1=1.0000209099982431\n",
      "GD iter. 58/99: loss=4.4601712106546225, w0=0.9995782838178109, w1=1.000021268444048\n",
      "GD iter. 59/99: loss=4.46010084523467, w0=0.9995711300752694, w1=1.0000216268195927\n",
      "GD iter. 60/99: loss=4.460030477319919, w0=0.9995639761322509, w1=1.0000219851248753\n",
      "GD iter. 61/99: loss=4.459960106924739, w0=0.9995568219887493, w1=1.0000223433598936\n",
      "GD iter. 62/99: loss=4.459889734036586, w0=0.9995496676447586, w1=1.0000227015246455\n",
      "GD iter. 63/99: loss=4.459819358657586, w0=0.9995425131002729, w1=1.0000230596191286\n",
      "GD iter. 64/99: loss=4.459748980787324, w0=0.9995353583552861, w1=1.000023417643341\n",
      "GD iter. 65/99: loss=4.459678600433581, w0=0.9995282034097921, w1=1.0000237755972803\n",
      "GD iter. 66/99: loss=4.459608217589396, w0=0.999521048263785, w1=1.0000241334809445\n",
      "GD iter. 67/99: loss=4.459537832256825, w0=0.9995138929172587, w1=1.0000244912943315\n",
      "GD iter. 68/99: loss=4.459467444443476, w0=0.9995067373702071, w1=1.000024849037439\n",
      "GD iter. 69/99: loss=4.459397054128887, w0=0.9994995816226243, w1=1.000025206710265\n",
      "GD iter. 70/99: loss=4.459326661336574, w0=0.9994924256745042, w1=1.0000255643128075\n",
      "GD iter. 71/99: loss=4.459256266054699, w0=0.9994852695258409, w1=1.000025921845064\n",
      "GD iter. 72/99: loss=4.459185868269801, w0=0.9994781131766283, w1=1.0000262793070325\n",
      "GD iter. 73/99: loss=4.459115468014827, w0=0.9994709566268603, w1=1.000026636698711\n",
      "GD iter. 74/99: loss=4.459045065266608, w0=0.9994637998765309, w1=1.000026994020097\n",
      "GD iter. 75/99: loss=4.458974660025023, w0=0.9994566429256342, w1=1.0000273512711886\n",
      "GD iter. 76/99: loss=4.458904252297218, w0=0.999449485774164, w1=1.0000277084519837\n",
      "GD iter. 77/99: loss=4.458833842082395, w0=0.9994423284221144, w1=1.00002806556248\n",
      "GD iter. 78/99: loss=4.458763429376788, w0=0.9994351708694793, w1=1.0000284226026754\n",
      "GD iter. 79/99: loss=4.458693014191928, w0=0.9994280131162527, w1=1.0000287795725677\n",
      "GD iter. 80/99: loss=4.4586225965136626, w0=0.9994208551624286, w1=1.000029136472155\n",
      "GD iter. 81/99: loss=4.458552176348343, w0=0.9994136970080009, w1=1.0000294933014349\n",
      "GD iter. 82/99: loss=4.458481753686837, w0=0.9994065386529636, w1=1.0000298500604052\n",
      "GD iter. 83/99: loss=4.4584113285408495, w0=0.9993993800973107, w1=1.0000302067490638\n",
      "GD iter. 84/99: loss=4.458340900914973, w0=0.9993922213410361, w1=1.0000305633674087\n",
      "GD iter. 85/99: loss=4.458270470803228, w0=0.9993850623841338, w1=1.0000309199154376\n",
      "GD iter. 86/99: loss=4.458200038190011, w0=0.9993779032265978, w1=1.0000312763931485\n",
      "GD iter. 87/99: loss=4.458129603096243, w0=0.9993707438684221, w1=1.0000316328005392\n",
      "GD iter. 88/99: loss=4.458059165515807, w0=0.9993635843096005, w1=1.0000319891376075\n",
      "GD iter. 89/99: loss=4.457988725448877, w0=0.9993564245501271, w1=1.0000323454043512\n",
      "GD iter. 90/99: loss=4.45791828289236, w0=0.9993492645899958, w1=1.0000327016007682\n",
      "GD iter. 91/99: loss=4.457847837851824, w0=0.9993421044292008, w1=1.0000330577268564\n",
      "GD iter. 92/99: loss=4.457777390316304, w0=0.9993349440677358, w1=1.0000334137826135\n",
      "GD iter. 93/99: loss=4.457706940297868, w0=0.9993277835055949, w1=1.0000337697680375\n",
      "GD iter. 94/99: loss=4.457636487790628, w0=0.999320622742772, w1=1.000034125683126\n",
      "GD iter. 95/99: loss=4.457566032792767, w0=0.9993134617792611, w1=1.0000344815278772\n",
      "GD iter. 96/99: loss=4.457495575313218, w0=0.9993063006150561, w1=1.0000348373022887\n",
      "GD iter. 97/99: loss=4.457425115348214, w0=0.999299139250151, w1=1.0000351930063585\n",
      "GD iter. 98/99: loss=4.457354652894498, w0=0.9992919776845398, w1=1.0000355486400843\n",
      "GD iter. 99/99: loss=4.457284187955503, w0=0.9992848159182164, w1=1.000035904203464\n",
      "0.59416\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.471240730602096, w0=0.9999928077793377, w1=1.0000003523110244\n",
      "GD iter. 1/99: loss=4.471170337849841, w0=0.9999856153581514, w1=1.0000007045519448\n",
      "GD iter. 2/99: loss=4.4710999426082685, w0=0.999978422736435, w1=1.0000010567227593\n",
      "GD iter. 3/99: loss=4.4710295448571955, w0=0.9999712299141823, w1=1.0000014088234654\n",
      "GD iter. 4/99: loss=4.470959144621728, w0=0.9999640368913872, w1=1.000001760854061\n",
      "GD iter. 5/99: loss=4.470888741885524, w0=0.9999568436680437, w1=1.0000021128145438\n",
      "GD iter. 6/99: loss=4.470818336656699, w0=0.9999496502441456, w1=1.0000024647049117\n",
      "GD iter. 7/99: loss=4.470747928933482, w0=0.9999424566196868, w1=1.0000028165251624\n",
      "GD iter. 8/99: loss=4.470677518714904, w0=0.9999352627946613, w1=1.0000031682752937\n",
      "GD iter. 9/99: loss=4.470607106002709, w0=0.9999280687690628, w1=1.0000035199553032\n",
      "GD iter. 10/99: loss=4.4705366907848, w0=0.9999208745428854, w1=1.0000038715651889\n",
      "GD iter. 11/99: loss=4.470466273084659, w0=0.9999136801161228, w1=1.0000042231049482\n",
      "GD iter. 12/99: loss=4.470395852890513, w0=0.999906485488769, w1=1.0000045745745791\n",
      "GD iter. 13/99: loss=4.470325430196333, w0=0.999899290660818, w1=1.0000049259740795\n",
      "GD iter. 14/99: loss=4.470255005004994, w0=0.9998920956322634, w1=1.0000052773034471\n",
      "GD iter. 15/99: loss=4.470184577328648, w0=0.9998849004030994, w1=1.0000056285626795\n",
      "GD iter. 16/99: loss=4.47011414714449, w0=0.9998777049733197, w1=1.0000059797517746\n",
      "GD iter. 17/99: loss=4.470043714467636, w0=0.9998705093429183, w1=1.00000633087073\n",
      "GD iter. 18/99: loss=4.469973279299699, w0=0.9998633135118891, w1=1.000006681919544\n",
      "GD iter. 19/99: loss=4.46990284163406, w0=0.9998561174802257, w1=1.0000070328982136\n",
      "GD iter. 20/99: loss=4.469832401482087, w0=0.9998489212479224, w1=1.000007383806737\n",
      "GD iter. 21/99: loss=4.4697619588287445, w0=0.9998417248149728, w1=1.0000077346451117\n",
      "GD iter. 22/99: loss=4.469691513682687, w0=0.999834528181371, w1=1.0000080854133357\n",
      "GD iter. 23/99: loss=4.469621066036923, w0=0.9998273313471107, w1=1.000008436111407\n",
      "GD iter. 24/99: loss=4.469550615907243, w0=0.9998201343121859, w1=1.000008786739323\n",
      "GD iter. 25/99: loss=4.4694801632743415, w0=0.9998129370765905, w1=1.0000091372970816\n",
      "GD iter. 26/99: loss=4.469409708153882, w0=0.9998057396403183, w1=1.0000094877846804\n",
      "GD iter. 27/99: loss=4.469339250531491, w0=0.9997985420033633, w1=1.0000098382021172\n",
      "GD iter. 28/99: loss=4.469268790418935, w0=0.9997913441657192, w1=1.00001018854939\n",
      "GD iter. 29/99: loss=4.469198327811671, w0=0.9997841461273801, w1=1.0000105388264964\n",
      "GD iter. 30/99: loss=4.4691278627079445, w0=0.9997769478883398, w1=1.000010889033434\n",
      "GD iter. 31/99: loss=4.469057395114327, w0=0.9997697494485922, w1=1.000011239170201\n",
      "GD iter. 32/99: loss=4.468986925026137, w0=0.9997625508081311, w1=1.0000115892367947\n",
      "GD iter. 33/99: loss=4.468916452448127, w0=0.9997553519669505, w1=1.0000119392332132\n",
      "GD iter. 34/99: loss=4.468845977362711, w0=0.9997481529250443, w1=1.000012289159454\n",
      "GD iter. 35/99: loss=4.468775499789949, w0=0.9997409536824062, w1=1.000012639015515\n",
      "GD iter. 36/99: loss=4.468705019724197, w0=0.9997337542390303, w1=1.000012988801394\n",
      "GD iter. 37/99: loss=4.468634537163867, w0=0.9997265545949104, w1=1.0000133385170886\n",
      "GD iter. 38/99: loss=4.468564052114215, w0=0.9997193547500404, w1=1.0000136881625967\n",
      "GD iter. 39/99: loss=4.468493564562089, w0=0.9997121547044141, w1=1.000014037737916\n",
      "GD iter. 40/99: loss=4.468423074518736, w0=0.9997049544580255, w1=1.0000143872430445\n",
      "GD iter. 41/99: loss=4.468352581988263, w0=0.9996977540108685, w1=1.0000147366779797\n",
      "GD iter. 42/99: loss=4.468282086955965, w0=0.9996905533629368, w1=1.0000150860427193\n",
      "GD iter. 43/99: loss=4.468211589436483, w0=0.9996833525142245, w1=1.0000154353372612\n",
      "GD iter. 44/99: loss=4.468141089417249, w0=0.9996761514647253, w1=1.0000157845616033\n",
      "GD iter. 45/99: loss=4.468070586903449, w0=0.9996689502144332, w1=1.0000161337157432\n",
      "GD iter. 46/99: loss=4.468000081902137, w0=0.9996617487633421, w1=1.0000164827996785\n",
      "GD iter. 47/99: loss=4.4679295744019925, w0=0.9996545471114457, w1=1.0000168318134073\n",
      "GD iter. 48/99: loss=4.467859064411301, w0=0.9996473452587381, w1=1.0000171807569271\n",
      "GD iter. 49/99: loss=4.467788551924968, w0=0.9996401432052131, w1=1.0000175296302358\n",
      "GD iter. 50/99: loss=4.467718036943072, w0=0.9996329409508645, w1=1.0000178784333311\n",
      "GD iter. 51/99: loss=4.467647519467865, w0=0.9996257384956863, w1=1.0000182271662108\n",
      "GD iter. 52/99: loss=4.467576999508564, w0=0.9996185358396722, w1=1.0000185758288727\n",
      "GD iter. 53/99: loss=4.467506477052106, w0=0.9996113329828162, w1=1.0000189244213145\n",
      "GD iter. 54/99: loss=4.467435952096286, w0=0.9996041299251123, w1=1.0000192729435338\n",
      "GD iter. 55/99: loss=4.467365424649247, w0=0.9995969266665542, w1=1.0000196213955286\n",
      "GD iter. 56/99: loss=4.46729489471314, w0=0.9995897232071359, w1=1.0000199697772965\n",
      "GD iter. 57/99: loss=4.467224362282294, w0=0.9995825195468512, w1=1.0000203180888354\n",
      "GD iter. 58/99: loss=4.467153827356387, w0=0.999575315685694, w1=1.000020666330143\n",
      "GD iter. 59/99: loss=4.467083289939587, w0=0.9995681116236582, w1=1.000021014501217\n",
      "GD iter. 60/99: loss=4.467012750025677, w0=0.9995609073607377, w1=1.000021362602055\n",
      "GD iter. 61/99: loss=4.466942207628941, w0=0.9995537028969262, w1=1.0000217106326552\n",
      "GD iter. 62/99: loss=4.466871662720796, w0=0.9995464982322178, w1=1.000022058593015\n",
      "GD iter. 63/99: loss=4.466801115337111, w0=0.9995392933666062, w1=1.0000224064831325\n",
      "GD iter. 64/99: loss=4.466730565457741, w0=0.9995320883000853, w1=1.0000227543030051\n",
      "GD iter. 65/99: loss=4.466660013068125, w0=0.9995248830326491, w1=1.000023102052631\n",
      "GD iter. 66/99: loss=4.466589458199907, w0=0.9995176775642913, w1=1.0000234497320073\n",
      "GD iter. 67/99: loss=4.4665189008404145, w0=0.999510471895006, w1=1.0000237973411323\n",
      "GD iter. 68/99: loss=4.466448340980815, w0=0.9995032660247869, w1=1.0000241448800036\n",
      "GD iter. 69/99: loss=4.4663777786474155, w0=0.999496059953628, w1=1.000024492348619\n",
      "GD iter. 70/99: loss=4.466307213804009, w0=0.9994888536815231, w1=1.0000248397469762\n",
      "GD iter. 71/99: loss=4.466236646469591, w0=0.999481647208466, w1=1.000025187075073\n",
      "GD iter. 72/99: loss=4.466166076639697, w0=0.9994744405344507, w1=1.000025534332907\n",
      "GD iter. 73/99: loss=4.466095504322273, w0=0.999467233659471, w1=1.0000258815204761\n",
      "GD iter. 74/99: loss=4.466024929511145, w0=0.9994600265835207, w1=1.0000262286377781\n",
      "GD iter. 75/99: loss=4.465954352203248, w0=0.9994528193065939, w1=1.0000265756848106\n",
      "GD iter. 76/99: loss=4.465883772409202, w0=0.9994456118286843, w1=1.0000269226615714\n",
      "GD iter. 77/99: loss=4.465813190123129, w0=0.9994384041497858, w1=1.0000272695680583\n",
      "GD iter. 78/99: loss=4.465742605337936, w0=0.9994311962698923, w1=1.0000276164042692\n",
      "GD iter. 79/99: loss=4.465672018066979, w0=0.9994239881889976, w1=1.0000279631702016\n",
      "GD iter. 80/99: loss=4.4656014282985765, w0=0.9994167799070955, w1=1.0000283098658533\n",
      "GD iter. 81/99: loss=4.465530836041361, w0=0.9994095714241802, w1=1.0000286564912222\n",
      "GD iter. 82/99: loss=4.465460241291549, w0=0.9994023627402452, w1=1.000029003046306\n",
      "GD iter. 83/99: loss=4.465389644042571, w0=0.9993951538552845, w1=1.0000293495311023\n",
      "GD iter. 84/99: loss=4.465319044304168, w0=0.9993879447692922, w1=1.0000296959456092\n",
      "GD iter. 85/99: loss=4.465248442082662, w0=0.9993807354822618, w1=1.0000300422898243\n",
      "GD iter. 86/99: loss=4.4651778373585005, w0=0.9993735259941874, w1=1.0000303885637452\n",
      "GD iter. 87/99: loss=4.465107230151047, w0=0.9993663163050628, w1=1.0000307347673698\n",
      "GD iter. 88/99: loss=4.465036620447771, w0=0.9993591064148818, w1=1.0000310809006958\n",
      "GD iter. 89/99: loss=4.464966008255402, w0=0.9993518963236383, w1=1.000031426963721\n",
      "GD iter. 90/99: loss=4.46489539356194, w0=0.9993446860313262, w1=1.000031772956443\n",
      "GD iter. 91/99: loss=4.464824776380164, w0=0.9993374755379394, w1=1.0000321188788597\n",
      "GD iter. 92/99: loss=4.464754156703939, w0=0.9993302648434718, w1=1.0000324647309689\n",
      "GD iter. 93/99: loss=4.464683534537717, w0=0.9993230539479171, w1=1.0000328105127683\n",
      "GD iter. 94/99: loss=4.464612909889957, w0=0.9993158428512693, w1=1.0000331562242557\n",
      "GD iter. 95/99: loss=4.4645422827425705, w0=0.9993086315535222, w1=1.0000335018654287\n",
      "GD iter. 96/99: loss=4.464471653102783, w0=0.9993014200546697, w1=1.0000338474362853\n",
      "GD iter. 97/99: loss=4.464401020968193, w0=0.9992942083547056, w1=1.000034192936823\n",
      "GD iter. 98/99: loss=4.464330386349568, w0=0.9992869964536238, w1=1.0000345383670397\n",
      "GD iter. 99/99: loss=4.464259749236912, w0=0.9992797843514183, w1=1.000034883726933\n",
      "0.59876\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.473322726857449, w0=0.9999928145362349, w1=1.0000003279652305\n",
      "GD iter. 1/99: loss=4.473252303633104, w0=0.9999856288714182, w1=1.000000655859953\n",
      "GD iter. 2/99: loss=4.473181877900903, w0=0.9999784430055438, w1=1.0000009836841652\n",
      "GD iter. 3/99: loss=4.4731114496686954, w0=0.999971256938606, w1=1.0000013114378652\n",
      "GD iter. 4/99: loss=4.473041018932578, w0=0.9999640706705986, w1=1.0000016391210507\n",
      "GD iter. 5/99: loss=4.472970585699177, w0=0.9999568842015155, w1=1.0000019667337197\n",
      "GD iter. 6/99: loss=4.472900149961494, w0=0.9999496975313509, w1=1.00000229427587\n",
      "GD iter. 7/99: loss=4.472829711722591, w0=0.9999425106600986, w1=1.0000026217474993\n",
      "GD iter. 8/99: loss=4.472759270989709, w0=0.9999353235877527, w1=1.0000029491486058\n",
      "GD iter. 9/99: loss=4.47268882775423, w0=0.9999281363143072, w1=1.000003276479187\n",
      "GD iter. 10/99: loss=4.472618382016576, w0=0.9999209488397561, w1=1.0000036037392412\n",
      "GD iter. 11/99: loss=4.4725479337803185, w0=0.9999137611640935, w1=1.000003930928766\n",
      "GD iter. 12/99: loss=4.472477483036344, w0=0.9999065732873131, w1=1.0000042580477593\n",
      "GD iter. 13/99: loss=4.472407029801758, w0=0.9998993852094092, w1=1.000004585096219\n",
      "GD iter. 14/99: loss=4.472336574070766, w0=0.9998921969303757, w1=1.000004912074143\n",
      "GD iter. 15/99: loss=4.47226611582884, w0=0.9998850084502064, w1=1.000005238981529\n",
      "GD iter. 16/99: loss=4.472195655091895, w0=0.9998778197688957, w1=1.000005565818375\n",
      "GD iter. 17/99: loss=4.472125191845104, w0=0.9998706308864372, w1=1.000005892584679\n",
      "GD iter. 18/99: loss=4.472054726106609, w0=0.9998634418028252, w1=1.0000062192804389\n",
      "GD iter. 19/99: loss=4.471984257863571, w0=0.9998562525180534, w1=1.0000065459056522\n",
      "GD iter. 20/99: loss=4.4719137871291235, w0=0.999849063032116, w1=1.000006872460317\n",
      "GD iter. 21/99: loss=4.471843313888179, w0=0.9998418733450068, w1=1.0000071989444312\n",
      "GD iter. 22/99: loss=4.471772838144059, w0=0.9998346834567201, w1=1.0000075253579928\n",
      "GD iter. 23/99: loss=4.471702359912309, w0=0.9998274933672496, w1=1.0000078517009994\n",
      "GD iter. 24/99: loss=4.471631879174193, w0=0.9998203030765895, w1=1.0000081779734489\n",
      "GD iter. 25/99: loss=4.471561395934338, w0=0.9998131125847337, w1=1.0000085041753393\n",
      "GD iter. 26/99: loss=4.471490910196585, w0=0.9998059218916762, w1=1.0000088303066683\n",
      "GD iter. 27/99: loss=4.471420421956203, w0=0.9997987309974109, w1=1.000009156367434\n",
      "GD iter. 28/99: loss=4.471349931215209, w0=0.9997915399019319, w1=1.0000094823576342\n",
      "GD iter. 29/99: loss=4.471279437982075, w0=0.9997843486052332, w1=1.0000098082772668\n",
      "GD iter. 30/99: loss=4.471208942244539, w0=0.9997771571073087, w1=1.0000101341263294\n",
      "GD iter. 31/99: loss=4.471138444002889, w0=0.9997699654081525, w1=1.0000104599048203\n",
      "GD iter. 32/99: loss=4.471067943277284, w0=0.9997627735077586, w1=1.000010785612737\n",
      "GD iter. 33/99: loss=4.470997440040838, w0=0.9997555814061209, w1=1.0000111112500776\n",
      "GD iter. 34/99: loss=4.470926934296996, w0=0.9997483891032334, w1=1.0000114368168398\n",
      "GD iter. 35/99: loss=4.470856426071954, w0=0.9997411965990901, w1=1.0000117623130216\n",
      "GD iter. 36/99: loss=4.470785915332994, w0=0.9997340038936849, w1=1.0000120877386207\n",
      "GD iter. 37/99: loss=4.470715402098657, w0=0.999726810987012, w1=1.0000124130936352\n",
      "GD iter. 38/99: loss=4.470644886365416, w0=0.9997196178790652, w1=1.0000127383780628\n",
      "GD iter. 39/99: loss=4.470574368130356, w0=0.9997124245698386, w1=1.0000130635919013\n",
      "GD iter. 40/99: loss=4.470503847406682, w0=0.9997052310593261, w1=1.0000133887351488\n",
      "GD iter. 41/99: loss=4.470433324175835, w0=0.9996980373475217, w1=1.0000137138078031\n",
      "GD iter. 42/99: loss=4.470362798445267, w0=0.9996908434344195, w1=1.000014038809862\n",
      "GD iter. 43/99: loss=4.470292270207079, w0=0.9996836493200133, w1=1.0000143637413232\n",
      "GD iter. 44/99: loss=4.4702217394881405, w0=0.9996764550042972, w1=1.000014688602185\n",
      "GD iter. 45/99: loss=4.4701512062570385, w0=0.9996692604872652, w1=1.000015013392445\n",
      "GD iter. 46/99: loss=4.470080670532383, w0=0.9996620657689113, w1=1.000015338112101\n",
      "GD iter. 47/99: loss=4.470010132302247, w0=0.9996548708492293, w1=1.0000156627611512\n",
      "GD iter. 48/99: loss=4.469939591585624, w0=0.9996476757282134, w1=1.000015987339593\n",
      "GD iter. 49/99: loss=4.46986904835486, w0=0.9996404804058576, w1=1.0000163118474246\n",
      "GD iter. 50/99: loss=4.469798502642203, w0=0.9996332848821557, w1=1.0000166362846437\n",
      "GD iter. 51/99: loss=4.469727954415141, w0=0.9996260891571018, w1=1.0000169606512481\n",
      "GD iter. 52/99: loss=4.469657403702919, w0=0.9996188932306899, w1=1.000017284947236\n",
      "GD iter. 53/99: loss=4.469586850484447, w0=0.9996116971029139, w1=1.000017609172605\n",
      "GD iter. 54/99: loss=4.469516294760459, w0=0.9996045007737677, w1=1.000017933327353\n",
      "GD iter. 55/99: loss=4.469445736550555, w0=0.9995973042432456, w1=1.0000182574114778\n",
      "GD iter. 56/99: loss=4.469375175841324, w0=0.9995901075113413, w1=1.0000185814249773\n",
      "GD iter. 57/99: loss=4.469304612619462, w0=0.9995829105780488, w1=1.0000189053678497\n",
      "GD iter. 58/99: loss=4.469234046910169, w0=0.9995757134433623, w1=1.0000192292400925\n",
      "GD iter. 59/99: loss=4.469163478703917, w0=0.9995685161072755, w1=1.0000195530417035\n",
      "GD iter. 60/99: loss=4.469092907993252, w0=0.9995613185697825, w1=1.000019876772681\n",
      "GD iter. 61/99: loss=4.469022334789763, w0=0.9995541208308772, w1=1.0000202004330223\n",
      "GD iter. 62/99: loss=4.468951759077036, w0=0.9995469228905538, w1=1.0000205240227256\n",
      "GD iter. 63/99: loss=4.468881180881655, w0=0.9995397247488061, w1=1.0000208475417887\n",
      "GD iter. 64/99: loss=4.468810600184252, w0=0.9995325264056282, w1=1.0000211709902094\n",
      "GD iter. 65/99: loss=4.468740016982537, w0=0.9995253278610139, w1=1.0000214943679857\n",
      "GD iter. 66/99: loss=4.468669431280264, w0=0.9995181291149573, w1=1.0000218176751154\n",
      "GD iter. 67/99: loss=4.4685988430782935, w0=0.9995109301674524, w1=1.0000221409115964\n",
      "GD iter. 68/99: loss=4.468528252387883, w0=0.9995037310184931, w1=1.0000224640774265\n",
      "GD iter. 69/99: loss=4.468457659196138, w0=0.9994965316680734, w1=1.0000227871726035\n",
      "GD iter. 70/99: loss=4.46838706351574, w0=0.9994893321161873, w1=1.0000231101971255\n",
      "GD iter. 71/99: loss=4.468316465327024, w0=0.9994821323628288, w1=1.0000234331509903\n",
      "GD iter. 72/99: loss=4.46824586463277, w0=0.9994749324079918, w1=1.0000237560341956\n",
      "GD iter. 73/99: loss=4.468175261456181, w0=0.9994677322516703, w1=1.0000240788467394\n",
      "GD iter. 74/99: loss=4.468104655766257, w0=0.9994605318938583, w1=1.0000244015886195\n",
      "GD iter. 75/99: loss=4.468034047588129, w0=0.9994533313345498, w1=1.0000247242598337\n",
      "GD iter. 76/99: loss=4.467963436909964, w0=0.9994461305737388, w1=1.00002504686038\n",
      "GD iter. 77/99: loss=4.467892823735603, w0=0.9994389296114191, w1=1.000025369390256\n",
      "GD iter. 78/99: loss=4.467822208052035, w0=0.9994317284475849, w1=1.00002569184946\n",
      "GD iter. 79/99: loss=4.467751589891593, w0=0.99942452708223, w1=1.0000260142379898\n",
      "GD iter. 80/99: loss=4.467680969220782, w0=0.9994173255153485, w1=1.0000263365558428\n",
      "GD iter. 81/99: loss=4.467610346053585, w0=0.9994101237469343, w1=1.0000266588030173\n",
      "GD iter. 82/99: loss=4.467539720391869, w0=0.9994029217769813, w1=1.000026980979511\n",
      "GD iter. 83/99: loss=4.467469092219752, w0=0.9993957196054837, w1=1.0000273030853217\n",
      "GD iter. 84/99: loss=4.467398461568976, w0=0.9993885172324353, w1=1.0000276251204474\n",
      "GD iter. 85/99: loss=4.467327828405118, w0=0.99938131465783, w1=1.0000279470848858\n",
      "GD iter. 86/99: loss=4.4672571927578, w0=0.9993741118816619, w1=1.000028268978635\n",
      "GD iter. 87/99: loss=4.467186554605202, w0=0.999366908903925, w1=1.0000285908016928\n",
      "GD iter. 88/99: loss=4.4671159139530845, w0=0.9993597057246132, w1=1.000028912554057\n",
      "GD iter. 89/99: loss=4.467045270800891, w0=0.9993525023437204, w1=1.0000292342357253\n",
      "GD iter. 90/99: loss=4.466974625155191, w0=0.9993452987612407, w1=1.0000295558466958\n",
      "GD iter. 91/99: loss=4.466903977023648, w0=0.999338094977168, w1=1.0000298773869662\n",
      "GD iter. 92/99: loss=4.466833326378769, w0=0.9993308909914963, w1=1.0000301988565345\n",
      "GD iter. 93/99: loss=4.466762673246869, w0=0.9993236868042196, w1=1.0000305202553985\n",
      "GD iter. 94/99: loss=4.466692017611246, w0=0.9993164824153318, w1=1.000030841583556\n",
      "GD iter. 95/99: loss=4.466621359479771, w0=0.9993092778248269, w1=1.0000311628410048\n",
      "GD iter. 96/99: loss=4.466550698859946, w0=0.9993020730326989, w1=1.000031484027743\n",
      "GD iter. 97/99: loss=4.46648003573803, w0=0.9992948680389417, w1=1.0000318051437682\n",
      "GD iter. 98/99: loss=4.466409370108016, w0=0.9992876628435493, w1=1.0000321261890786\n",
      "GD iter. 99/99: loss=4.466338701997554, w0=0.9992804574465157, w1=1.0000324471636717\n",
      "0.60124\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.47244150942526, w0=0.9999927609260415, w1=1.0000003867982696\n",
      "GD iter. 1/99: loss=4.472371136768039, w0=0.9999855216511226, w1=1.0000007735260057\n",
      "GD iter. 2/99: loss=4.472300761617748, w0=0.9999782821752374, w1=1.0000011601832064\n",
      "GD iter. 3/99: loss=4.472230383970074, w0=0.9999710424983799, w1=1.0000015467698693\n",
      "GD iter. 4/99: loss=4.472160003834913, w0=0.999963802620544, w1=1.0000019332859926\n",
      "GD iter. 5/99: loss=4.472089621206488, w0=0.9999565625417237, w1=1.0000023197315742\n",
      "GD iter. 6/99: loss=4.472019236085411, w0=0.999949322261913, w1=1.0000027061066117\n",
      "GD iter. 7/99: loss=4.471948848461329, w0=0.999942081781106, w1=1.0000030924111032\n",
      "GD iter. 8/99: loss=4.47187845836532, w0=0.9999348410992966, w1=1.0000034786450465\n",
      "GD iter. 9/99: loss=4.4718080657662584, w0=0.999927600216479, w1=1.0000038648084395\n",
      "GD iter. 10/99: loss=4.471737670673116, w0=0.9999203591326469, w1=1.00000425090128\n",
      "GD iter. 11/99: loss=4.4716672730843445, w0=0.9999131178477945, w1=1.0000046369235662\n",
      "GD iter. 12/99: loss=4.471596873005931, w0=0.9999058763619156, w1=1.000005022875296\n",
      "GD iter. 13/99: loss=4.471526470433967, w0=0.9998986346750045, w1=1.000005408756467\n",
      "GD iter. 14/99: loss=4.471456065369053, w0=0.999891392787055, w1=1.000005794567077\n",
      "GD iter. 15/99: loss=4.471385657810185, w0=0.999884150698061, w1=1.0000061803071243\n",
      "GD iter. 16/99: loss=4.471315247766072, w0=0.9998769084080167, w1=1.0000065659766066\n",
      "GD iter. 17/99: loss=4.471244835217661, w0=0.999869665916916, w1=1.0000069515755219\n",
      "GD iter. 18/99: loss=4.471174420189104, w0=0.9998624232247528, w1=1.0000073371038678\n",
      "GD iter. 19/99: loss=4.471104002659114, w0=0.9998551803315213, w1=1.0000077225616424\n",
      "GD iter. 20/99: loss=4.471033582643233, w0=0.9998479372372154, w1=1.0000081079488436\n",
      "GD iter. 21/99: loss=4.470963160134436, w0=0.9998406939418292, w1=1.0000084932654694\n",
      "GD iter. 22/99: loss=4.470892735126155, w0=0.9998334504453564, w1=1.0000088785115173\n",
      "GD iter. 23/99: loss=4.470822307632613, w0=0.9998262067477913, w1=1.0000092636869855\n",
      "GD iter. 24/99: loss=4.470751877653123, w0=0.9998189628491277, w1=1.000009648791872\n",
      "GD iter. 25/99: loss=4.470681445168567, w0=0.9998117187493598, w1=1.0000100338261744\n",
      "GD iter. 26/99: loss=4.470611010196256, w0=0.9998044744484814, w1=1.0000104187898906\n",
      "GD iter. 27/99: loss=4.4705405727327445, w0=0.9997972299464866, w1=1.0000108036830186\n",
      "GD iter. 28/99: loss=4.4704701327764855, w0=0.9997899852433693, w1=1.0000111885055565\n",
      "GD iter. 29/99: loss=4.470399690335321, w0=0.9997827403391235, w1=1.000011573257502\n",
      "GD iter. 30/99: loss=4.4703292453884, w0=0.9997754952337432, w1=1.0000119579388527\n",
      "GD iter. 31/99: loss=4.470258797953879, w0=0.9997682499272225, w1=1.0000123425496068\n",
      "GD iter. 32/99: loss=4.4701883480380085, w0=0.9997610044195553, w1=1.0000127270897623\n",
      "GD iter. 33/99: loss=4.470117895623638, w0=0.9997537587107356, w1=1.000013111559317\n",
      "GD iter. 34/99: loss=4.470047440711065, w0=0.9997465128007573, w1=1.0000134959582685\n",
      "GD iter. 35/99: loss=4.469976983314589, w0=0.9997392666896145, w1=1.0000138802866152\n",
      "GD iter. 36/99: loss=4.469906523427848, w0=0.9997320203773012, w1=1.0000142645443546\n",
      "GD iter. 37/99: loss=4.469836061036491, w0=0.9997247738638114, w1=1.0000146487314847\n",
      "GD iter. 38/99: loss=4.469765596169391, w0=0.999717527149139, w1=1.0000150328480035\n",
      "GD iter. 39/99: loss=4.469695128804001, w0=0.999710280233278, w1=1.0000154168939088\n",
      "GD iter. 40/99: loss=4.469624658948478, w0=0.9997030331162224, w1=1.0000158008691984\n",
      "GD iter. 41/99: loss=4.469554186600875, w0=0.9996957857979663, w1=1.0000161847738702\n",
      "GD iter. 42/99: loss=4.469483711753417, w0=0.9996885382785036, w1=1.0000165686079223\n",
      "GD iter. 43/99: loss=4.469413234424118, w0=0.9996812905578282, w1=1.0000169523713525\n",
      "GD iter. 44/99: loss=4.469342754597202, w0=0.9996740426359342, w1=1.0000173360641584\n",
      "GD iter. 45/99: loss=4.4692722722858305, w0=0.9996667945128156, w1=1.0000177196863382\n",
      "GD iter. 46/99: loss=4.469201787477701, w0=0.9996595461884663, w1=1.0000181032378899\n",
      "GD iter. 47/99: loss=4.469131300179175, w0=0.9996522976628803, w1=1.000018486718811\n",
      "GD iter. 48/99: loss=4.469060810389158, w0=0.9996450489360517, w1=1.0000188701290997\n",
      "GD iter. 49/99: loss=4.468990318109101, w0=0.9996378000079743, w1=1.0000192534687538\n",
      "GD iter. 50/99: loss=4.4689198233436285, w0=0.9996305508786423, w1=1.000019636737771\n",
      "GD iter. 51/99: loss=4.468849326075972, w0=0.9996233015480495, w1=1.0000200199361493\n",
      "GD iter. 52/99: loss=4.468778826324363, w0=0.9996160520161899, w1=1.0000204030638868\n",
      "GD iter. 53/99: loss=4.468708324077294, w0=0.9996088022830575, w1=1.0000207861209813\n",
      "GD iter. 54/99: loss=4.4686378193431935, w0=0.9996015523486463, w1=1.0000211691074306\n",
      "GD iter. 55/99: loss=4.468567312111393, w0=0.9995943022129504, w1=1.0000215520232325\n",
      "GD iter. 56/99: loss=4.468496802396223, w0=0.9995870518759638, w1=1.000021934868385\n",
      "GD iter. 57/99: loss=4.468426290189015, w0=0.9995798013376802, w1=1.000022317642886\n",
      "GD iter. 58/99: loss=4.468355775485688, w0=0.9995725505980938, w1=1.0000227003467332\n",
      "GD iter. 59/99: loss=4.46828525829108, w0=0.9995652996571985, w1=1.0000230829799248\n",
      "GD iter. 60/99: loss=4.468214738612203, w0=0.9995580485149884, w1=1.0000234655424585\n",
      "GD iter. 61/99: loss=4.46814421644014, w0=0.9995507971714573, w1=1.0000238480343322\n",
      "GD iter. 62/99: loss=4.468073691773992, w0=0.9995435456265993, w1=1.0000242304555438\n",
      "GD iter. 63/99: loss=4.468003164623811, w0=0.9995362938804083, w1=1.0000246128060912\n",
      "GD iter. 64/99: loss=4.467932634980002, w0=0.9995290419328784, w1=1.0000249950859723\n",
      "GD iter. 65/99: loss=4.4678621028366825, w0=0.9995217897840035, w1=1.000025377295185\n",
      "GD iter. 66/99: loss=4.467791568212568, w0=0.9995145374337776, w1=1.0000257594337272\n",
      "GD iter. 67/99: loss=4.467721031097454, w0=0.9995072848821946, w1=1.0000261415015967\n",
      "GD iter. 68/99: loss=4.467650491486031, w0=0.9995000321292487, w1=1.0000265234987915\n",
      "GD iter. 69/99: loss=4.467579949392778, w0=0.9994927791749336, w1=1.0000269054253095\n",
      "GD iter. 70/99: loss=4.4675094048044315, w0=0.9994855260192435, w1=1.0000272872811484\n",
      "GD iter. 71/99: loss=4.4674388577274415, w0=0.9994782726621722, w1=1.0000276690663061\n",
      "GD iter. 72/99: loss=4.4673683081550735, w0=0.9994710191037137, w1=1.0000280507807806\n",
      "GD iter. 73/99: loss=4.4672977560995, w0=0.9994637653438622, w1=1.0000284324245698\n",
      "GD iter. 74/99: loss=4.467227201543382, w0=0.9994565113826114, w1=1.0000288139976716\n",
      "GD iter. 75/99: loss=4.467156644492766, w0=0.9994492572199554, w1=1.0000291955000837\n",
      "GD iter. 76/99: loss=4.467086084963137, w0=0.9994420028558881, w1=1.0000295769318042\n",
      "GD iter. 77/99: loss=4.467015522952706, w0=0.9994347482904037, w1=1.0000299582928307\n",
      "GD iter. 78/99: loss=4.46694495843125, w0=0.9994274935234959, w1=1.0000303395831613\n",
      "GD iter. 79/99: loss=4.466874391431993, w0=0.9994202385551588, w1=1.0000307208027939\n",
      "GD iter. 80/99: loss=4.466803821939873, w0=0.9994129833853864, w1=1.0000311019517263\n",
      "GD iter. 81/99: loss=4.46673324995661, w0=0.9994057280141727, w1=1.0000314830299566\n",
      "GD iter. 82/99: loss=4.46666267548549, w0=0.9993984724415116, w1=1.0000318640374823\n",
      "GD iter. 83/99: loss=4.46659209851851, w0=0.999391216667397, w1=1.0000322449743015\n",
      "GD iter. 84/99: loss=4.466521519067483, w0=0.9993839606918231, w1=1.0000326258404122\n",
      "GD iter. 85/99: loss=4.466450937120678, w0=0.9993767045147837, w1=1.000033006635812\n",
      "GD iter. 86/99: loss=4.466380352695317, w0=0.9993694481362727, w1=1.0000333873604992\n",
      "GD iter. 87/99: loss=4.466309765767913, w0=0.9993621915562843, w1=1.0000337680144713\n",
      "GD iter. 88/99: loss=4.4662391763577425, w0=0.9993549347748123, w1=1.0000341485977262\n",
      "GD iter. 89/99: loss=4.466168584453656, w0=0.9993476777918507, w1=1.000034529110262\n",
      "GD iter. 90/99: loss=4.46609799006998, w0=0.9993404206073936, w1=1.0000349095520764\n",
      "GD iter. 91/99: loss=4.466027393181956, w0=0.9993331632214347, w1=1.0000352899231675\n",
      "GD iter. 92/99: loss=4.4659567938040965, w0=0.9993259056339683, w1=1.000035670223533\n",
      "GD iter. 93/99: loss=4.465886191944425, w0=0.9993186478449881, w1=1.0000360504531707\n",
      "GD iter. 94/99: loss=4.465815587590839, w0=0.9993113898544883, w1=1.0000364306120786\n",
      "GD iter. 95/99: loss=4.465744980751487, w0=0.9993041316624627, w1=1.0000368107002546\n",
      "GD iter. 96/99: loss=4.4656743714239315, w0=0.9992968732689053, w1=1.0000371907176966\n",
      "GD iter. 97/99: loss=4.465603759605598, w0=0.9992896146738101, w1=1.0000375706644025\n",
      "GD iter. 98/99: loss=4.465533145295293, w0=0.999282355877171, w1=1.00003795054037\n",
      "GD iter. 99/99: loss=4.465462528503251, w0=0.999275096878982, w1=1.0000383303455973\n",
      "0.59832\n",
      "(225000, 31)\n",
      "(225000,)\n",
      "(31,)\n",
      "GD iter. 0/99: loss=4.477863044342005, w0=0.999992793487722, w1=1.0000003935402015\n",
      "GD iter. 1/99: loss=4.477792486440327, w0=0.9999855867742986, w1=1.0000007870094851\n",
      "GD iter. 2/99: loss=4.477721926018905, w0=0.9999783798597239, w1=1.0000011804078486\n",
      "GD iter. 3/99: loss=4.4776513630727095, w0=0.999971172743992, w1=1.0000015737352896\n",
      "GD iter. 4/99: loss=4.477580797626254, w0=0.9999639654270969, w1=1.0000019669918063\n",
      "GD iter. 5/99: loss=4.477510229655574, w0=0.9999567579090323, w1=1.0000023601773964\n",
      "GD iter. 6/99: loss=4.4774396591638235, w0=0.9999495501897924, w1=1.0000027532920577\n",
      "GD iter. 7/99: loss=4.477369086150958, w0=0.9999423422693712, w1=1.0000031463357881\n",
      "GD iter. 8/99: loss=4.477298510635779, w0=0.9999351341477626, w1=1.0000035393085855\n",
      "GD iter. 9/99: loss=4.4772279326062465, w0=0.9999279258249607, w1=1.000003932210448\n",
      "GD iter. 10/99: loss=4.4771573520508525, w0=0.9999207173009594, w1=1.000004325041373\n",
      "GD iter. 11/99: loss=4.477086768990807, w0=0.9999135085757528, w1=1.0000047178013587\n",
      "GD iter. 12/99: loss=4.477016183404205, w0=0.9999062996493346, w1=1.0000051104904026\n",
      "GD iter. 13/99: loss=4.476945595302306, w0=0.9998990905216991, w1=1.000005503108503\n",
      "GD iter. 14/99: loss=4.476875004683387, w0=0.9998918811928402, w1=1.0000058956556572\n",
      "GD iter. 15/99: loss=4.47680441155716, w0=0.9998846716627519, w1=1.0000062881318637\n",
      "GD iter. 16/99: loss=4.476733815903997, w0=0.999877461931428, w1=1.00000668053712\n",
      "GD iter. 17/99: loss=4.476663217745169, w0=0.9998702519988627, w1=1.0000070728714239\n",
      "GD iter. 18/99: loss=4.476592617067559, w0=0.9998630418650499, w1=1.0000074651347735\n",
      "GD iter. 19/99: loss=4.476522013877496, w0=0.9998558315299837, w1=1.0000078573271665\n",
      "GD iter. 20/99: loss=4.476451408167538, w0=0.9998486209936579, w1=1.0000082494486007\n",
      "GD iter. 21/99: loss=4.476380799952547, w0=0.9998414102560665, w1=1.000008641499074\n",
      "GD iter. 22/99: loss=4.476310189201008, w0=0.9998341993172036, w1=1.0000090334785845\n",
      "GD iter. 23/99: loss=4.476239575954661, w0=0.9998269881770632, w1=1.0000094253871297\n",
      "GD iter. 24/99: loss=4.476168960182288, w0=0.9998197768356392, w1=1.0000098172247076\n",
      "GD iter. 25/99: loss=4.476098341901581, w0=0.9998125652929255, w1=1.000010208991316\n",
      "GD iter. 26/99: loss=4.4760277210982675, w0=0.9998053535489163, w1=1.000010600686953\n",
      "GD iter. 27/99: loss=4.475957097781453, w0=0.9997981416036055, w1=1.0000109923116158\n",
      "GD iter. 28/99: loss=4.475886471948087, w0=0.999790929456987, w1=1.0000113838653029\n",
      "GD iter. 29/99: loss=4.475815843606523, w0=0.9997837171090548, w1=1.000011775348012\n",
      "GD iter. 30/99: loss=4.475745212753636, w0=0.9997765045598029, w1=1.0000121667597408\n",
      "GD iter. 31/99: loss=4.475674579367695, w0=0.9997692918092254, w1=1.0000125581004873\n",
      "GD iter. 32/99: loss=4.475603943481795, w0=0.999762078857316, w1=1.0000129493702494\n",
      "GD iter. 33/99: loss=4.475533305075112, w0=0.999754865704069, w1=1.0000133405690248\n",
      "GD iter. 34/99: loss=4.475462664151676, w0=0.9997476523494782, w1=1.0000137316968114\n",
      "GD iter. 35/99: loss=4.475392020721876, w0=0.9997404387935375, w1=1.0000141227536072\n",
      "GD iter. 36/99: loss=4.475321374775372, w0=0.9997332250362411, w1=1.0000145137394099\n",
      "GD iter. 37/99: loss=4.475250726305537, w0=0.9997260110775827, w1=1.0000149046542173\n",
      "GD iter. 38/99: loss=4.475180075330666, w0=0.9997187969175566, w1=1.0000152954980275\n",
      "GD iter. 39/99: loss=4.475109421827768, w0=0.9997115825561566, w1=1.000015686270838\n",
      "GD iter. 40/99: loss=4.475038765820814, w0=0.9997043679933767, w1=1.000016076972647\n",
      "GD iter. 41/99: loss=4.474968107303639, w0=0.9996971532292108, w1=1.000016467603452\n",
      "GD iter. 42/99: loss=4.474897446264453, w0=0.999689938263653, w1=1.0000168581632511\n",
      "GD iter. 43/99: loss=4.474826782708135, w0=0.9996827230966974, w1=1.0000172486520422\n",
      "GD iter. 44/99: loss=4.474756116638102, w0=0.9996755077283377, w1=1.000017639069823\n",
      "GD iter. 45/99: loss=4.474685448054443, w0=0.999668292158568, w1=1.0000180294165915\n",
      "GD iter. 46/99: loss=4.474614776962681, w0=0.9996610763873822, w1=1.0000184196923454\n",
      "GD iter. 47/99: loss=4.4745441033441, w0=0.9996538604147743, w1=1.0000188098970826\n",
      "GD iter. 48/99: loss=4.4744734272251385, w0=0.9996466442407385, w1=1.000019200030801\n",
      "GD iter. 49/99: loss=4.474402748583471, w0=0.9996394278652684, w1=1.0000195900934985\n",
      "GD iter. 50/99: loss=4.474332067438012, w0=0.9996322112883582, w1=1.0000199800851728\n",
      "GD iter. 51/99: loss=4.474261383760476, w0=0.9996249945100019, w1=1.0000203700058217\n",
      "GD iter. 52/99: loss=4.47419069757637, w0=0.9996177775301933, w1=1.0000207598554431\n",
      "GD iter. 53/99: loss=4.474120008882879, w0=0.9996105603489266, w1=1.000021149634035\n",
      "GD iter. 54/99: loss=4.474049317671237, w0=0.9996033429661956, w1=1.0000215393415952\n",
      "GD iter. 55/99: loss=4.473978623946973, w0=0.9995961253819943, w1=1.0000219289781216\n",
      "GD iter. 56/99: loss=4.473907927708341, w0=0.9995889075963167, w1=1.000022318543612\n",
      "GD iter. 57/99: loss=4.473837228957741, w0=0.9995816896091568, w1=1.000022708038064\n",
      "GD iter. 58/99: loss=4.473766527683748, w0=0.9995744714205086, w1=1.0000230974614757\n",
      "GD iter. 59/99: loss=4.473695823903859, w0=0.999567253030366, w1=1.000023486813845\n",
      "GD iter. 60/99: loss=4.473625117619454, w0=0.999560034438723, w1=1.0000238760951696\n",
      "GD iter. 61/99: loss=4.473554408802008, w0=0.9995528156455735, w1=1.0000242653054474\n",
      "GD iter. 62/99: loss=4.473483697479666, w0=0.9995455966509116, w1=1.0000246544446763\n",
      "GD iter. 63/99: loss=4.47341298364164, w0=0.9995383774547312, w1=1.0000250435128542\n",
      "GD iter. 64/99: loss=4.473342267289438, w0=0.9995311580570262, w1=1.0000254325099787\n",
      "GD iter. 65/99: loss=4.473271548423547, w0=0.9995239384577906, w1=1.0000258214360478\n",
      "GD iter. 66/99: loss=4.473200827054408, w0=0.9995167186570185, w1=1.0000262102910595\n",
      "GD iter. 67/99: loss=4.473130103158646, w0=0.9995094986547038, w1=1.0000265990750115\n",
      "GD iter. 68/99: loss=4.473059376750285, w0=0.9995022784508405, w1=1.0000269877879016\n",
      "GD iter. 69/99: loss=4.472988647836212, w0=0.9994950580454224, w1=1.0000273764297276\n",
      "GD iter. 70/99: loss=4.47291791640969, w0=0.9994878374384436, w1=1.0000277650004876\n",
      "GD iter. 71/99: loss=4.472847182459686, w0=0.9994806166298981, w1=1.0000281535001794\n",
      "GD iter. 72/99: loss=4.472776445993203, w0=0.9994733956197798, w1=1.0000285419288006\n",
      "GD iter. 73/99: loss=4.472705707023672, w0=0.9994661744080826, w1=1.0000289302863492\n",
      "GD iter. 74/99: loss=4.472634965538447, w0=0.9994589529948006, w1=1.000029318572823\n",
      "GD iter. 75/99: loss=4.472564221540967, w0=0.9994517313799277, w1=1.00002970678822\n",
      "GD iter. 76/99: loss=4.472493475028762, w0=0.9994445095634579, w1=1.000030094932538\n",
      "GD iter. 77/99: loss=4.472422725999948, w0=0.9994372875453852, w1=1.0000304830057747\n",
      "GD iter. 78/99: loss=4.4723519744591, w0=0.9994300653257034, w1=1.000030871007928\n",
      "GD iter. 79/99: loss=4.472281220408912, w0=0.9994228429044067, w1=1.000031258938996\n",
      "GD iter. 80/99: loss=4.47221046384346, w0=0.999415620281489, w1=1.000031646798976\n",
      "GD iter. 81/99: loss=4.472139704760238, w0=0.9994083974569441, w1=1.0000320345878664\n",
      "GD iter. 82/99: loss=4.472068943170431, w0=0.999401174430766, w1=1.0000324223056647\n",
      "GD iter. 83/99: loss=4.471998179068761, w0=0.9993939512029488, w1=1.000032809952369\n",
      "GD iter. 84/99: loss=4.471927412447899, w0=0.9993867277734865, w1=1.000033197527977\n",
      "GD iter. 85/99: loss=4.471856643316997, w0=0.9993795041423729, w1=1.0000335850324866\n",
      "GD iter. 86/99: loss=4.471785871666686, w0=0.999372280309602, w1=1.0000339724658955\n",
      "GD iter. 87/99: loss=4.4717150975104785, w0=0.9993650562751678, w1=1.0000343598282018\n",
      "GD iter. 88/99: loss=4.47164432084918, w0=0.9993578320390643, w1=1.000034747119403\n",
      "GD iter. 89/99: loss=4.471573541663005, w0=0.9993506076012852, w1=1.0000351343394973\n",
      "GD iter. 90/99: loss=4.471502759965093, w0=0.9993433829618249, w1=1.0000355214884824\n",
      "GD iter. 91/99: loss=4.471431975761899, w0=0.999336158120677, w1=1.0000359085663562\n",
      "GD iter. 92/99: loss=4.471361189033859, w0=0.9993289330778357, w1=1.0000362955731164\n",
      "GD iter. 93/99: loss=4.471290399800102, w0=0.9993217078332948, w1=1.000036682508761\n",
      "GD iter. 94/99: loss=4.471219608054321, w0=0.9993144823870482, w1=1.0000370693732878\n",
      "GD iter. 95/99: loss=4.471148813802805, w0=0.9993072567390902, w1=1.0000374561666947\n",
      "GD iter. 96/99: loss=4.471078017027463, w0=0.9993000308894143, w1=1.0000378428889793\n",
      "GD iter. 97/99: loss=4.471007217743996, w0=0.9992928048380149, w1=1.0000382295401398\n",
      "GD iter. 98/99: loss=4.470936415947436, w0=0.9992855785848856, w1=1.0000386161201738\n",
      "GD iter. 99/99: loss=4.470865611638211, w0=0.9992783521300206, w1=1.000039002629079\n",
      "0.60104\n",
      "[0.5999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99927961 1.00003636 0.9989018  0.99936969 0.9979869  0.99693027\n",
      " 0.997372   0.99692511 1.00133343 0.99859147 0.99737267 0.99849069\n",
      " 0.99905064 0.99692884 0.9999135  0.99959867 0.99976548 0.99835578\n",
      " 0.9995783  0.99982242 0.99841324 0.99972998 0.9974947  0.99672255\n",
      " 0.99736528 0.99743541 0.99743641 0.99692825 0.99692846 0.99692842\n",
      " 0.99728839]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    # split data in k fold\n",
    "seed = 1\n",
    "k_fold = 10\n",
    "lambdas = np.logspace(-10, -2,  1)\n",
    "k_indices = build_k_indices(y_tr, k_fold, seed)\n",
    "rmse_tr = np.zeros((lambdas.shape[0], 1))\n",
    "rmse_te =  np.zeros((lambdas.shape[0], 1))\n",
    "w_poss = np.zeros((lambdas.shape[0], tx_tr.shape[1]+1))\n",
    "gamma = 0.0001\n",
    "max_iters = 100\n",
    "acc = np.zeros((lambdas.shape[0], 1))\n",
    "f1 = np.zeros((lambdas.shape[0], 1))\n",
    "    \n",
    "    # cross validation over lambdas and degrees:\n",
    "for j, lambda_ in enumerate(lambdas):\n",
    "            \n",
    "            loss_tr_k = []\n",
    "            loss_te_k = []\n",
    "            acc_k = []\n",
    "            f1_k = []\n",
    "            w_k = np.zeros((k_fold, tx_tr.shape[1]+1))\n",
    "            i =0\n",
    "            for k in range(k_fold):\n",
    "                loss_tr, loss_te, w, acc_i, f1_i = cross_validation(y_tr, tx_tr, k_indices, k, lambda_, max_iters, gamma)\n",
    "                loss_tr_k.append(loss_tr)\n",
    "                loss_te_k.append(loss_te)\n",
    "                acc_k.append(acc_i)\n",
    "                f1_k.append(f1_i)\n",
    "                print(acc_i)\n",
    "                w_k[i, :] = w\n",
    "                i=i+1\n",
    "w_poss[j, :]  = np.mean(w_k, axis=0)\n",
    "acc[j] = np.mean(acc_k)  \n",
    "print(acc[j])     \n",
    "f1[j] = np.mean(f1_k)\n",
    "rmse_tr[j] = np.mean(loss_tr_k)\n",
    "rmse_te[j] = np.mean(loss_te_k)\n",
    "max_idx = np.unravel_index(f1.argmax(), f1.shape)\n",
    "\n",
    "best_lambda = lambdas[max_idx[1]]\n",
    "best_rmse = np.min(rmse_te) \n",
    "best_w = w_poss[max_idx[1], :]\n",
    "best_acc = acc[max_idx[1]]\n",
    "best_f1 = f1[max_idx[1]]\n",
    "plt.plot(lambdas, rmse_tr, 'ro', lambdas, rmse_te, 'bo')\n",
    "plt.show()\n",
    "print(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5999])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model achieves 0.60 accuracy and 0.47 F1 score on test set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-999.   ,   79.589,   23.916, ..., -999.   , -999.   ,    0.   ],\n",
       "       [ 106.398,   67.49 ,   87.949, ..., -999.   , -999.   ,   47.575],\n",
       "       [ 117.794,   56.226,   96.358, ..., -999.   , -999.   ,    0.   ],\n",
       "       ...,\n",
       "       [ 108.497,    9.837,   65.149, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  96.711,   20.006,   66.942, ..., -999.   , -999.   ,   30.863],\n",
       "       [  92.373,   80.109,   77.619, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model achieves {:.2f} accuracy and {:.2f} F1 score on test set.\".format(best_acc[0], best_f1[0]))\n",
    "\n",
    "y_test, x_test, ids_test = load_csv_data('data/test.csv', sub_sample=False)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 31 is different from 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb Cellule 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred \u001b[39m=\u001b[39m predict(x_test, best_w)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred[y_pred \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m create_csv_submission(ids_test, y_pred , \u001b[39m'\u001b[39m\u001b[39msubmission.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb Cellule 11\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x, w)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(x, w):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(x \u001b[39m@\u001b[39;49m w)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     y_pred[sigmoid(x \u001b[39m@\u001b[39m w)  \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matteopeduto/Documents/GitHub/ml-project-1-los_caballeros_de_bogota/Train_mat.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y_pred[sigmoid(x \u001b[39m@\u001b[39m w) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 31 is different from 30)"
     ]
    }
   ],
   "source": [
    "y_pred = predict(x_test, best_w)\n",
    "y_pred[y_pred == 0] = -1\n",
    "create_csv_submission(ids_test, y_pred , 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(568238, 0), dtype=float64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8029b478de32fdc1aa34081dedd11fb14ac97854dbafe5aac8002b51b3d44b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
